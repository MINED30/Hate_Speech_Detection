{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HATESPEECH_08_(Modeling_with_FinalDataset_02).ipynb",
      "provenance": [],
      "collapsed_sections": [
        "p4EtcTm-XbJ0",
        "7XW6Rsj2tIp1",
        "xUN5gdJ6H05q",
        "1UovRoImH3ho"
      ],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "dbc87d4ddb864afeac0883ea0042166e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_b72028fdea4c4167b47652dced522441",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4b09b153e65a47e5beb94bfb4b7841df",
              "IPY_MODEL_7208c750014f4ca2ba3f513326023dcf"
            ]
          }
        },
        "b72028fdea4c4167b47652dced522441": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4b09b153e65a47e5beb94bfb4b7841df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_31b26f36f56f44ca8c9af52f355c70a2",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 500,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 500,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b6d5be63d50f463cbb4ae94704ee6dc2"
          }
        },
        "7208c750014f4ca2ba3f513326023dcf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_db962db78f59452bbfc1edd4938a5b16",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 500/500 [00:59&lt;00:00, 8.45B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d391dc79b01a41cda0faef8e6915c629"
          }
        },
        "31b26f36f56f44ca8c9af52f355c70a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b6d5be63d50f463cbb4ae94704ee6dc2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "db962db78f59452bbfc1edd4938a5b16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d391dc79b01a41cda0faef8e6915c629": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "518522089a0b4391ae33bcb4f50cd1f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f48f6eb020124bb0b106566a8133bb92",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_0f81759bb35340638d7f7be0bd4b3455",
              "IPY_MODEL_b5235cd9ae0c44ef9bb9eecc29d97f74"
            ]
          }
        },
        "f48f6eb020124bb0b106566a8133bb92": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0f81759bb35340638d7f7be0bd4b3455": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_508e78db52084cc9ae8b61b68e57f3a1",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231580,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231580,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3a98e12163d04b00bb055291b10f05bd"
          }
        },
        "b5235cd9ae0c44ef9bb9eecc29d97f74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e98c59b787dd45b0a840de4d52cb4bb1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:01&lt;00:00, 199kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_37e827aa64bd4ab7b03dbd718f36fdc9"
          }
        },
        "508e78db52084cc9ae8b61b68e57f3a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3a98e12163d04b00bb055291b10f05bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e98c59b787dd45b0a840de4d52cb4bb1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "37e827aa64bd4ab7b03dbd718f36fdc9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cf26d4181bfb4500b8dff410842eb4df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_873dc06a32e0438ca0f495475cffbdb1",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_0107964b116a4a0486683bac33e5c8de",
              "IPY_MODEL_06f712a47d194f5bab9fc52cd4a53e82"
            ]
          }
        },
        "873dc06a32e0438ca0f495475cffbdb1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0107964b116a4a0486683bac33e5c8de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_38a445396068498da2dc87e5c3dc1ed6",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 466182,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 466182,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9cc6459b00f846518e46a83872a43008"
          }
        },
        "06f712a47d194f5bab9fc52cd4a53e82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7aab0542f7ed49088eb3f07c4b259f03",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 466k/466k [00:00&lt;00:00, 559kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c1c4f7f30ca44cfa8bc44ef4d0dfb7fd"
          }
        },
        "38a445396068498da2dc87e5c3dc1ed6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9cc6459b00f846518e46a83872a43008": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7aab0542f7ed49088eb3f07c4b259f03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c1c4f7f30ca44cfa8bc44ef4d0dfb7fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4eea3f15f3e947ce964349ab92a826f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_eebe3ca29c1540b5b1f6c0d8f5ee28fd",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_bae7d4988d2645f1bd24fcebea64cf88",
              "IPY_MODEL_815d80e2a1f347e68ff6f2f953be68d6"
            ]
          }
        },
        "eebe3ca29c1540b5b1f6c0d8f5ee28fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bae7d4988d2645f1bd24fcebea64cf88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_98dcd8712c3a4b29a08145a318844634",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 103473649,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 103473649,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bc64b6f2ba3046d9a720c0974d192d0d"
          }
        },
        "815d80e2a1f347e68ff6f2f953be68d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8595be04032445c1bbe014472fa47cfd",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 103M/103M [00:02&lt;00:00, 46.5MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_59211b77d2ca4f09a6cb9dcde796c7e1"
          }
        },
        "98dcd8712c3a4b29a08145a318844634": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bc64b6f2ba3046d9a720c0974d192d0d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8595be04032445c1bbe014472fa47cfd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "59211b77d2ca4f09a6cb9dcde796c7e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pOKbZqLItGLO"
      },
      "source": [
        "# Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Q1BY82t3_sK",
        "outputId": "17a4b366-c1ad-4fd4-c241-fed267db1ecf"
      },
      "source": [
        "import time\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score\n",
        "from sklearn.utils import shuffle\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "import warnings\n",
        "warnings.filterwarnings(action='ignore')\n",
        "\n",
        "# Train dataset / Validation dataset\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/HateSpeech/FINAL_DATASET/Final_dataset_balanced.csv\")\n",
        "df = df.dropna()\n",
        "df_train, df_val = train_test_split(df,test_size=0.2,random_state = 42)\n",
        "# Test dataset\n",
        "df_test = pd.read_csv(\"/content/drive/MyDrive/HateSpeech/hateXplain.csv\")\n",
        "print(df_train.shape,df_val.shape,df_test.shape)\n",
        "\n",
        "df_train = df_train[(df_train['text'].apply(len)<1000)]\n",
        "df_val = df_val[(df_val['text'].apply(len)<1000)]\n",
        "df_test = df_test[(df_test['text'].apply(len)<1000)]\n",
        "print(df_train.shape,df_val.shape,df_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(123424, 3) (30856, 3) (15351, 3)\n",
            "(119868, 3) (29931, 3) (15351, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p4EtcTm-XbJ0"
      },
      "source": [
        "# 1 GloVe + RF,LGBM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7XW6Rsj2tIp1"
      },
      "source": [
        "### GloVe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_thYmpO08ZWH",
        "outputId": "7f1e1b0c-caec-4528-88eb-1abf78de45f7"
      },
      "source": [
        "import numpy as np\n",
        "embeddings_index = {}\n",
        "f = open(\"/content/drive/MyDrive/HateSpeech/glove.6B.100d.txt\")\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "f.close()\n",
        "\n",
        "print('Found %s word vectors.' % len(embeddings_index))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 400000 word vectors.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_d0Lto5-YKP"
      },
      "source": [
        "from keras.initializers import Constant\n",
        "from keras.layers import *\n",
        "\n",
        "X_train = df_train['text']\n",
        "y_train = df_train['class']\n",
        "X_val = df_val['text']\n",
        "y_val = df_val['class']\n",
        "X_test = df_test['text']\n",
        "y_test = df_test['class']\n",
        "\n",
        "# Initialization\n",
        "max_features=100000\n",
        "sequence_length = 235\n",
        "embedding_dim = 100\n",
        "num_words = 100001\n",
        "\n",
        "# Tokenizing\n",
        "data_start = time.time()\n",
        "tokenizer = Tokenizer(num_words=max_features, split=' ', oov_token='<unw>', filters=' ')\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "X_train = pad_sequences(tokenizer.texts_to_sequences(X_train), sequence_length)\n",
        "\n",
        "word_index = tokenizer.word_index\n",
        "embedding_matrix_train = np.zeros((num_words, embedding_dim))\n",
        "\n",
        "for word, i in word_index.items():\n",
        "    if i > max_features:\n",
        "        continue\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix_train[i] = embedding_vector\n",
        "    else:\n",
        "        embedding_matrix_train[i] = np.random.randn(embedding_dim)\n",
        "\n",
        "embed_keras = Embedding(num_words,\n",
        "                      embedding_dim,\n",
        "                      embeddings_initializer=Constant(embedding_matrix_train),\n",
        "                      input_length=sequence_length,\n",
        "                      trainable=True)\n",
        "\n",
        "X_val = pad_sequences(tokenizer.texts_to_sequences(X_val), sequence_length)\n",
        "X_test = pad_sequences(tokenizer.texts_to_sequences(X_test), sequence_length)\n",
        "\n",
        "X_train = embed_keras(X_train).numpy().reshape(X_train.shape[0],23500)\n",
        "X_val = embed_keras(X_val).numpy().reshape(X_val.shape[0],23500)\n",
        "X_test = embed_keras(X_test).numpy().reshape(X_test.shape[0],23500)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P719YRM1tKF4"
      },
      "source": [
        "### RF,LGBM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vC43he9c-wDI",
        "outputId": "425f53b7-baca-4dd4-ef67-76a425a7db1a"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "model_list = []\n",
        "model_list.append([RandomForestClassifier(max_depth=None,min_samples_split=4,n_estimators=100,oob_score=False,n_jobs=-1,verbose=10),\n",
        "                  'RandomForestClassifier'])\n",
        "model_list.append([LGBMClassifier(),'LGBMClassifier'])\n",
        "model_list"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                         criterion='gini', max_depth=None, max_features='auto',\n",
              "                         max_leaf_nodes=None, max_samples=None,\n",
              "                         min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                         min_samples_leaf=1, min_samples_split=4,\n",
              "                         min_weight_fraction_leaf=0.0, n_estimators=100,\n",
              "                         n_jobs=-1, oob_score=False, random_state=None,\n",
              "                         verbose=10, warm_start=False),\n",
              "  'RandomForestClassifier'],\n",
              " [LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
              "                 importance_type='split', learning_rate=0.1, max_depth=-1,\n",
              "                 min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
              "                 n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,\n",
              "                 random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
              "                 subsample=1.0, subsample_for_bin=200000, subsample_freq=0),\n",
              "  'LGBMClassifier']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 155
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zCBnusF_tVQF"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AeRrCaL3_-2C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "397daa8e-d8e9-4459-b3c9-66e3b28c5d31"
      },
      "source": [
        "eval = pd.DataFrame([[np.nan for i in range(11)]])\n",
        "eval.columns = ['Model',\n",
        "                'Train_Score(ACC)','Train_Score(ROC_AUC)','Train_Score(F1)',\n",
        "                'Val_Score(ACC)','Val_Score(ROC_AUC)','Val_Score(F1)',\n",
        "                'Test_Score(ACC)','Test_Score(ROC_AUC)','Test_Score(F1)','Inference_Time']\n",
        "eval = eval.iloc[1:]\n",
        "\n",
        "for LR, model_name in model_list:\n",
        "\n",
        "  # Fit\n",
        "  print(f\"{model_name}\",\"-\"*100)\n",
        "  LR.fit(X_train,y_train)\n",
        "\n",
        "  # Inference\n",
        "  print(\"TRAIN SET\")\n",
        "  fitted = LR.predict(X_train)\n",
        "  fitted_proba = LR.predict_proba(X_train)\n",
        "\n",
        "  print(\"VAL SET\")\n",
        "  val_pred = LR.predict(X_val)\n",
        "  val_pred_proba = LR.predict_proba(X_val)\n",
        "\n",
        "  print(\"TEST SET\")\n",
        "  start = time.time()\n",
        "  test_pred = LR.predict(X_test)\n",
        "  inference_time = time.time()-start\n",
        "  test_pred_proba = LR.predict_proba(X_test)\n",
        "  print(f\"Inferenced : {inference_time}s\",end='\\t')\n",
        "\n",
        "  # Evaluate\n",
        "  train_acc = accuracy_score(y_train,fitted)\n",
        "  train_auc = roc_auc_score(y_train,fitted_proba[:,1])\n",
        "  train_f1 = f1_score(y_train,fitted)\n",
        "\n",
        "  val_acc = accuracy_score(y_val,val_pred)\n",
        "  val_auc = roc_auc_score(y_val,val_pred_proba[:,1])\n",
        "  val_f1 = f1_score(y_val,val_pred)\n",
        "\n",
        "  test_acc = accuracy_score(y_test,test_pred)\n",
        "  test_auc = roc_auc_score(y_test,test_pred_proba[:,1])\n",
        "  test_f1 = f1_score(y_test,test_pred)\n",
        "  print(f\"TRAIN ROC_AUC : {train_auc} VAL ROC_AUC : {val_auc} TEST ROC_AUC : {test_auc}\")\n",
        "\n",
        "  LR_list = [f\"{model_name}\"]\n",
        "  LR_list.append(train_acc)\n",
        "  LR_list.append(train_auc)\n",
        "  LR_list.append(train_f1)\n",
        "  LR_list.append(val_acc)\n",
        "  LR_list.append(val_auc)\n",
        "  LR_list.append(val_f1)\n",
        "  LR_list.append(test_acc)\n",
        "  LR_list.append(test_auc)\n",
        "  LR_list.append(test_f1)\n",
        "  LR_list.append(inference_time)\n",
        "  print(f\"DONE!!! {time.time()-data_start}\")\n",
        "  eval = eval.append(pd.DataFrame([LR_list],columns=eval.columns))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RandomForestClassifier ----------------------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 40 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "building tree 1 of 100building tree 2 of 100\n",
            "building tree 3 of 100\n",
            "building tree 4 of 100\n",
            "\n",
            "building tree 5 of 100\n",
            "building tree 6 of 100\n",
            "building tree 7 of 100building tree 8 of 100\n",
            "building tree 9 of 100\n",
            "building tree 10 of 100\n",
            "building tree 11 of 100\n",
            "building tree 12 of 100\n",
            "\n",
            "building tree 13 of 100\n",
            "building tree 14 of 100\n",
            "building tree 15 of 100\n",
            "building tree 16 of 100\n",
            "building tree 17 of 100\n",
            "building tree 18 of 100\n",
            "building tree 19 of 100\n",
            "building tree 20 of 100\n",
            "building tree 21 of 100\n",
            "building tree 22 of 100\n",
            "building tree 23 of 100\n",
            "building tree 24 of 100\n",
            "building tree 25 of 100\n",
            "building tree 26 of 100\n",
            "building tree 27 of 100\n",
            "building tree 28 of 100\n",
            "building tree 29 of 100\n",
            "building tree 30 of 100\n",
            "building tree 31 of 100\n",
            "building tree 32 of 100\n",
            "building tree 33 of 100building tree 34 of 100\n",
            "building tree 35 of 100\n",
            "\n",
            "building tree 36 of 100building tree 37 of 100\n",
            "building tree 38 of 100\n",
            "\n",
            "building tree 39 of 100\n",
            "building tree 40 of 100\n",
            "building tree 41 of 100\n",
            "building tree 42 of 100\n",
            "building tree 43 of 100\n",
            "building tree 44 of 100\n",
            "building tree 45 of 100\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:   16.1s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "building tree 46 of 100\n",
            "building tree 47 of 100\n",
            "building tree 48 of 100\n",
            "building tree 49 of 100\n",
            "building tree 50 of 100\n",
            "building tree 51 of 100\n",
            "building tree 52 of 100\n",
            "building tree 53 of 100building tree 54 of 100\n",
            "\n",
            "building tree 55 of 100\n",
            "building tree 56 of 100\n",
            "building tree 57 of 100\n",
            "building tree 58 of 100\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:   16.6s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "building tree 59 of 100\n",
            "building tree 60 of 100\n",
            "building tree 61 of 100\n",
            "building tree 62 of 100\n",
            "building tree 63 of 100\n",
            "building tree 64 of 100\n",
            "building tree 65 of 100\n",
            "building tree 66 of 100\n",
            "building tree 67 of 100\n",
            "building tree 68 of 100\n",
            "building tree 69 of 100\n",
            "building tree 70 of 100\n",
            "building tree 71 of 100\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done  32 out of 100 | elapsed:   17.2s remaining:   36.5s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "building tree 72 of 100\n",
            "building tree 73 of 100\n",
            "building tree 74 of 100\n",
            "building tree 75 of 100\n",
            "building tree 76 of 100\n",
            "building tree 77 of 100\n",
            "building tree 78 of 100\n",
            "building tree 79 of 100\n",
            "building tree 80 of 100\n",
            "building tree 81 of 100\n",
            "building tree 82 of 100\n",
            "building tree 83 of 100\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done  43 out of 100 | elapsed:   33.1s remaining:   43.8s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "building tree 84 of 100\n",
            "building tree 85 of 100\n",
            "building tree 86 of 100\n",
            "building tree 87 of 100\n",
            "building tree 88 of 100\n",
            "building tree 89 of 100\n",
            "building tree 90 of 100\n",
            "building tree 91 of 100\n",
            "building tree 92 of 100\n",
            "building tree 93 of 100\n",
            "building tree 94 of 100\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done  54 out of 100 | elapsed:   33.8s remaining:   28.8s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "building tree 95 of 100\n",
            "building tree 96 of 100\n",
            "building tree 97 of 100\n",
            "building tree 98 of 100\n",
            "building tree 99 of 100\n",
            "building tree 100 of 100\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done  65 out of 100 | elapsed:   34.4s remaining:   18.5s\n",
            "[Parallel(n_jobs=-1)]: Done  76 out of 100 | elapsed:   34.9s remaining:   11.0s\n",
            "[Parallel(n_jobs=-1)]: Done  87 out of 100 | elapsed:   45.0s remaining:    6.7s\n",
            "[Parallel(n_jobs=-1)]: Done  98 out of 100 | elapsed:   45.7s remaining:    0.9s\n",
            "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   45.8s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "TRAIN SET\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=40)]: Using backend ThreadingBackend with 40 concurrent workers.\n",
            "[Parallel(n_jobs=40)]: Done   5 tasks      | elapsed:    0.2s\n",
            "[Parallel(n_jobs=40)]: Done  18 tasks      | elapsed:    0.2s\n",
            "[Parallel(n_jobs=40)]: Done  32 out of 100 | elapsed:    0.2s remaining:    0.4s\n",
            "[Parallel(n_jobs=40)]: Done  43 out of 100 | elapsed:    0.3s remaining:    0.5s\n",
            "[Parallel(n_jobs=40)]: Done  54 out of 100 | elapsed:    0.4s remaining:    0.3s\n",
            "[Parallel(n_jobs=40)]: Done  65 out of 100 | elapsed:    0.4s remaining:    0.2s\n",
            "[Parallel(n_jobs=40)]: Done  76 out of 100 | elapsed:    0.4s remaining:    0.1s\n",
            "[Parallel(n_jobs=40)]: Done  87 out of 100 | elapsed:    0.5s remaining:    0.1s\n",
            "[Parallel(n_jobs=40)]: Done  98 out of 100 | elapsed:    0.5s remaining:    0.0s\n",
            "[Parallel(n_jobs=40)]: Done 100 out of 100 | elapsed:    0.5s finished\n",
            "[Parallel(n_jobs=40)]: Using backend ThreadingBackend with 40 concurrent workers.\n",
            "[Parallel(n_jobs=40)]: Done   5 tasks      | elapsed:    0.2s\n",
            "[Parallel(n_jobs=40)]: Done  18 tasks      | elapsed:    0.2s\n",
            "[Parallel(n_jobs=40)]: Done  32 out of 100 | elapsed:    0.2s remaining:    0.4s\n",
            "[Parallel(n_jobs=40)]: Done  43 out of 100 | elapsed:    0.3s remaining:    0.5s\n",
            "[Parallel(n_jobs=40)]: Done  54 out of 100 | elapsed:    0.4s remaining:    0.3s\n",
            "[Parallel(n_jobs=40)]: Done  65 out of 100 | elapsed:    0.4s remaining:    0.2s\n",
            "[Parallel(n_jobs=40)]: Done  76 out of 100 | elapsed:    0.4s remaining:    0.1s\n",
            "[Parallel(n_jobs=40)]: Done  87 out of 100 | elapsed:    0.5s remaining:    0.1s\n",
            "[Parallel(n_jobs=40)]: Done  98 out of 100 | elapsed:    0.5s remaining:    0.0s\n",
            "[Parallel(n_jobs=40)]: Done 100 out of 100 | elapsed:    0.5s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "VAL SET\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=40)]: Using backend ThreadingBackend with 40 concurrent workers.\n",
            "[Parallel(n_jobs=40)]: Done   5 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=40)]: Done  18 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=40)]: Done  32 out of 100 | elapsed:    0.1s remaining:    0.2s\n",
            "[Parallel(n_jobs=40)]: Done  43 out of 100 | elapsed:    0.1s remaining:    0.1s\n",
            "[Parallel(n_jobs=40)]: Done  54 out of 100 | elapsed:    0.1s remaining:    0.1s\n",
            "[Parallel(n_jobs=40)]: Done  65 out of 100 | elapsed:    0.1s remaining:    0.1s\n",
            "[Parallel(n_jobs=40)]: Done  76 out of 100 | elapsed:    0.1s remaining:    0.0s\n",
            "[Parallel(n_jobs=40)]: Done  87 out of 100 | elapsed:    0.1s remaining:    0.0s\n",
            "[Parallel(n_jobs=40)]: Done  98 out of 100 | elapsed:    0.2s remaining:    0.0s\n",
            "[Parallel(n_jobs=40)]: Done 100 out of 100 | elapsed:    0.2s finished\n",
            "[Parallel(n_jobs=40)]: Using backend ThreadingBackend with 40 concurrent workers.\n",
            "[Parallel(n_jobs=40)]: Done   5 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=40)]: Done  18 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=40)]: Done  32 out of 100 | elapsed:    0.1s remaining:    0.2s\n",
            "[Parallel(n_jobs=40)]: Done  43 out of 100 | elapsed:    0.1s remaining:    0.1s\n",
            "[Parallel(n_jobs=40)]: Done  54 out of 100 | elapsed:    0.1s remaining:    0.1s\n",
            "[Parallel(n_jobs=40)]: Done  65 out of 100 | elapsed:    0.1s remaining:    0.1s\n",
            "[Parallel(n_jobs=40)]: Done  76 out of 100 | elapsed:    0.1s remaining:    0.0s\n",
            "[Parallel(n_jobs=40)]: Done  87 out of 100 | elapsed:    0.1s remaining:    0.0s\n",
            "[Parallel(n_jobs=40)]: Done  98 out of 100 | elapsed:    0.2s remaining:    0.0s\n",
            "[Parallel(n_jobs=40)]: Done 100 out of 100 | elapsed:    0.2s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "TEST SET\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=40)]: Using backend ThreadingBackend with 40 concurrent workers.\n",
            "[Parallel(n_jobs=40)]: Done   5 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=40)]: Done  18 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=40)]: Done  32 out of 100 | elapsed:    0.1s remaining:    0.1s\n",
            "[Parallel(n_jobs=40)]: Done  43 out of 100 | elapsed:    0.1s remaining:    0.1s\n",
            "[Parallel(n_jobs=40)]: Done  54 out of 100 | elapsed:    0.1s remaining:    0.1s\n",
            "[Parallel(n_jobs=40)]: Done  65 out of 100 | elapsed:    0.1s remaining:    0.0s\n",
            "[Parallel(n_jobs=40)]: Done  76 out of 100 | elapsed:    0.1s remaining:    0.0s\n",
            "[Parallel(n_jobs=40)]: Done  87 out of 100 | elapsed:    0.1s remaining:    0.0s\n",
            "[Parallel(n_jobs=40)]: Done  98 out of 100 | elapsed:    0.1s remaining:    0.0s\n",
            "[Parallel(n_jobs=40)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
            "[Parallel(n_jobs=40)]: Using backend ThreadingBackend with 40 concurrent workers.\n",
            "[Parallel(n_jobs=40)]: Done   5 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=40)]: Done  18 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=40)]: Done  32 out of 100 | elapsed:    0.1s remaining:    0.1s\n",
            "[Parallel(n_jobs=40)]: Done  43 out of 100 | elapsed:    0.1s remaining:    0.1s\n",
            "[Parallel(n_jobs=40)]: Done  54 out of 100 | elapsed:    0.1s remaining:    0.1s\n",
            "[Parallel(n_jobs=40)]: Done  65 out of 100 | elapsed:    0.1s remaining:    0.0s\n",
            "[Parallel(n_jobs=40)]: Done  76 out of 100 | elapsed:    0.1s remaining:    0.0s\n",
            "[Parallel(n_jobs=40)]: Done  87 out of 100 | elapsed:    0.1s remaining:    0.0s\n",
            "[Parallel(n_jobs=40)]: Done  98 out of 100 | elapsed:    0.1s remaining:    0.0s\n",
            "[Parallel(n_jobs=40)]: Done 100 out of 100 | elapsed:    0.1s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Inferenced : 0.4736795425415039s\tTRAIN ROC_AUC : 0.9998535635659462 VAL ROC_AUC : 0.8158714488156463 TEST ROC_AUC : 0.4780614791794996\n",
            "DONE!!! 344.44000720977783\n",
            "LGBMClassifier ----------------------------------------------------------------------------------------------------\n",
            "TRAIN SET\n",
            "VAL SET\n",
            "TEST SET\n",
            "Inferenced : 0.10757231712341309s\tTRAIN ROC_AUC : 0.9042332544962901 VAL ROC_AUC : 0.8789744439192967 TEST ROC_AUC : 0.4840430921144571\n",
            "DONE!!! 502.0091800689697\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "El6O9kigtmU7"
      },
      "source": [
        "eval['Model'] = eval['Model']+'_GloVe_EMBED'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "id": "l9DOJT1ttpzg",
        "outputId": "a9f641df-e359-4a72-e578-b11323b2a4f2"
      },
      "source": [
        "eval"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Train_Score(ACC)</th>\n",
              "      <th>Train_Score(ROC_AUC)</th>\n",
              "      <th>Train_Score(F1)</th>\n",
              "      <th>Val_Score(ACC)</th>\n",
              "      <th>Val_Score(ROC_AUC)</th>\n",
              "      <th>Val_Score(F1)</th>\n",
              "      <th>Test_Score(ACC)</th>\n",
              "      <th>Test_Score(ROC_AUC)</th>\n",
              "      <th>Test_Score(F1)</th>\n",
              "      <th>Inference_Time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>RandomForestClassifier_GloVe_EMBED</td>\n",
              "      <td>0.998665</td>\n",
              "      <td>0.999854</td>\n",
              "      <td>0.998685</td>\n",
              "      <td>0.732919</td>\n",
              "      <td>0.815871</td>\n",
              "      <td>0.724687</td>\n",
              "      <td>0.444271</td>\n",
              "      <td>0.478061</td>\n",
              "      <td>0.334607</td>\n",
              "      <td>0.473680</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>LGBMClassifier_GloVe_EMBED</td>\n",
              "      <td>0.822096</td>\n",
              "      <td>0.904233</td>\n",
              "      <td>0.816286</td>\n",
              "      <td>0.794494</td>\n",
              "      <td>0.878974</td>\n",
              "      <td>0.781779</td>\n",
              "      <td>0.437235</td>\n",
              "      <td>0.484043</td>\n",
              "      <td>0.349130</td>\n",
              "      <td>0.107572</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                Model  ...  Inference_Time\n",
              "0  RandomForestClassifier_GloVe_EMBED  ...        0.473680\n",
              "0          LGBMClassifier_GloVe_EMBED  ...        0.107572\n",
              "\n",
              "[2 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 161
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FHXczRHgvjZj"
      },
      "source": [
        "eval.to_csv(f\"/content/drive/MyDrive/HateSpeech/PERFORMANCE2/ML_GloVe.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tnhup29yLbpd"
      },
      "source": [
        "# 2 Build Bert Embedded Dataset (DistilBERT)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7hzaOdD2Hrh-"
      },
      "source": [
        "## BERT TOKENIZER"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_kyrrVELcq2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a064ea9-99ed-4605-dc98-0c5197d1130d"
      },
      "source": [
        "pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fd/1a/41c644c963249fd7f3836d926afa1e3f1cc234a1c40d80c5f03ad8f6f1b2/transformers-4.8.2-py3-none-any.whl (2.5MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2.5MB 7.7MB/s \n",
            "\u001b[?25hCollecting huggingface-hub==0.0.12\n",
            "  Downloading https://files.pythonhosted.org/packages/2f/ee/97e253668fda9b17e968b3f97b2f8e53aa0127e8807d24a547687423fe0b/huggingface_hub-0.0.12-py3-none-any.whl\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 901kB 64.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from transformers) (3.13)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/e2/df3543e8ffdab68f5acc73f613de9c2b155ac47f162e725dcac87c521c11/tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.3MB 52.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub==0.0.12->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Installing collected packages: huggingface-hub, sacremoses, tokenizers, transformers\n",
            "Successfully installed huggingface-hub-0.0.12 sacremoses-0.0.45 tokenizers-0.10.3 transformers-4.8.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1rDpnMNmLjOF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04c8f16f-ae11-4efe-f62a-0539231d5446"
      },
      "source": [
        "from transformers import ElectraTokenizer, TFElectraForSequenceClassification\n",
        "\n",
        "tokenizer = ElectraTokenizer.from_pretrained('google/electra-small-discriminator')\n",
        "model = TFElectraForSequenceClassification.from_pretrained('google/electra-small-discriminator')\n",
        "model.load_weights(\"/content/drive/MyDrive/HateSpeech/Weight/ELECTRA\")\n",
        "model = tf.keras.Sequential(model.layers[:-1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at google/electra-small-discriminator were not used when initializing TFElectraForSequenceClassification: ['discriminator_predictions']\n",
            "- This IS expected if you are initializing TFElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some layers of TFElectraForSequenceClassification were not initialized from the model checkpoint at google/electra-small-discriminator and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LGCaeDmfHu9x"
      },
      "source": [
        "### BUILD DATASET"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nVWA3iSaLqII",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d356c4c-767c-4a5a-99c6-b0e70c839867"
      },
      "source": [
        "import time\n",
        "\n",
        "X_train = df_train['text'].to_list()\n",
        "y_train = df_train['class'].to_list()\n",
        "X_val = df_val['text'].to_list()\n",
        "y_val = df_val['class'].to_list()\n",
        "X_test = df_test['text'].to_list()\n",
        "y_test = df_test['class'].to_list()\n",
        "\n",
        "# Tokenizing\n",
        "encoding_time = time.time()\n",
        "train_encodings = tokenizer(X_train, truncation=True, padding=True)\n",
        "val_encodings = tokenizer(X_val, truncation=True, padding=True)\n",
        "test_encodings = tokenizer(X_test, truncation=True, padding=True)\n",
        "print(\"encoding time : \", time.time()-encoding_time)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "encoding time :  109.29729127883911\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ltyp9mkVj1Gr"
      },
      "source": [
        "# building dataset :  279.47532629966736\n",
        "# building dataset :  337.6722948551178"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZGILqi_HtDlA",
        "outputId": "06b1c3d6-9edd-46a6-a502-23c7c8722acb"
      },
      "source": [
        "# Build Dataset\n",
        "dataset_time = time.time()\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((\n",
        "    dict(train_encodings),\n",
        "    y_train\n",
        "))\n",
        "print(\"building dataset : \", time.time()-dataset_time)\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((\n",
        "    dict(val_encodings),\n",
        "    y_val\n",
        "))\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((\n",
        "    dict(test_encodings),\n",
        "    y_test\n",
        "))\n",
        "print(\"building dataset : \", time.time()-dataset_time)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "building dataset :  353.823668718338\n",
            "building dataset :  428.4043426513672\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xUN5gdJ6H05q"
      },
      "source": [
        "### SAVE DATASET"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s5KPOtpMEg_D"
      },
      "source": [
        "tf.data.experimental.save(\n",
        "    train_dataset, \"/content/drive/MyDrive/HateSpeech/traindataset_tf\", compression='GZIP'\n",
        ")\n",
        "with open(\"/content/drive/MyDrive/HateSpeech/traindataset_tf\" + '/element_spec', 'wb') as out_:  # also save the element_spec to disk for future loading\n",
        "    pickle.dump(train_dataset.element_spec, out_)\n",
        "\n",
        "tf.data.experimental.save(\n",
        "    val_dataset, \"/content/drive/MyDrive/HateSpeech/valdataset_tf\", compression='GZIP'\n",
        ")\n",
        "with open(\"/content/drive/MyDrive/HateSpeech/valdataset_tf\" + '/element_spec', 'wb') as out_:  # also save the element_spec to disk for future loading\n",
        "    pickle.dump(val_dataset.element_spec, out_)\n",
        "\n",
        "tf.data.experimental.save(\n",
        "    test_dataset, \"/content/drive/MyDrive/HateSpeech/testdataset_tf\", compression='GZIP'\n",
        ")\n",
        "with open(\"/content/drive/MyDrive/HateSpeech/testdataset_tf\" + '/element_spec', 'wb') as out_:  # also save the element_spec to disk for future loading\n",
        "    pickle.dump(test_dataset.element_spec, out_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1UovRoImH3ho"
      },
      "source": [
        "### Load DATASET"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5n1g5EigENGj"
      },
      "source": [
        "import pickle\n",
        "with open( \"/content/drive/MyDrive/HateSpeech/traindataset_tf\" + '/element_spec', 'rb') as in_:\n",
        "    es = pickle.load(in_)\n",
        "\n",
        "train_dataset = tf.data.experimental.load(\n",
        "     \"/content/drive/MyDrive/HateSpeech/traindataset_tf\", es, compression='GZIP'\n",
        ")\n",
        "\n",
        "with open( \"/content/drive/MyDrive/HateSpeech/valdataset_tf\" + '/element_spec', 'rb') as in_:\n",
        "    es = pickle.load(in_)\n",
        "\n",
        "val_dataset = tf.data.experimental.load(\n",
        "     \"/content/drive/MyDrive/HateSpeech/valdataset_tf\", es, compression='GZIP'\n",
        ")\n",
        "\n",
        "with open( \"/content/drive/MyDrive/HateSpeech/testdataset_tf\" + '/element_spec', 'rb') as in_:\n",
        "    es = pickle.load(in_)\n",
        "\n",
        "test_dataset = tf.data.experimental.load(\n",
        "     \"/content/drive/MyDrive/HateSpeech/testdataset_tf\", es, compression='GZIP'\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2EWvrwAI4s1"
      },
      "source": [
        "## EMBEDDING"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mnhOvsHpuC55"
      },
      "source": [
        "### SAVE EMBEDDED DATASET"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rz-5wCOyS0wu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e9f6bba-9c1c-46d4-bfb6-18caa0826e3a"
      },
      "source": [
        "# save\n",
        "i=0\n",
        "start = time.time()\n",
        "for pred in train_dataset.batch(64):\n",
        "  if i%10==0 : \n",
        "    lef = len(df_train)/64\n",
        "    print(i,'/',int(lef),end='\\t')\n",
        "    ela = time.time()-start\n",
        "    print(round(ela,0),'s',end='\\t')\n",
        "    print(round(ela*(lef-i)/10,0),'s',end='\\t')\n",
        "    if i>0:print(\"SHAPE :\",temp.shape,y_temp.shape)\n",
        "    start = time.time()\n",
        "  if i == 0:\n",
        "    temp = model.predict(pred[0])[0][:,0,:]\n",
        "    y_temp = pred[1]\n",
        "    i+=1\n",
        "  else :\n",
        "    temp = np.append(temp,model.predict(pred[0])[0][:,0,:],axis=0)\n",
        "    y_temp = np.append(y_temp,pred[1])\n",
        "    i+=1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 / 1872\t0.0 s\t29.0 s\t10 / 1872\t3.0 s\t633.0 s\tSHAPE : (640, 256) (640,)\n",
            "20 / 1872\t3.0 s\t628.0 s\tSHAPE : (1280, 256) (1280,)\n",
            "30 / 1872\t3.0 s\t629.0 s\tSHAPE : (1920, 256) (1920,)\n",
            "40 / 1872\t3.0 s\t624.0 s\tSHAPE : (2560, 256) (2560,)\n",
            "50 / 1872\t3.0 s\t622.0 s\tSHAPE : (3200, 256) (3200,)\n",
            "60 / 1872\t3.0 s\t620.0 s\tSHAPE : (3840, 256) (3840,)\n",
            "70 / 1872\t3.0 s\t617.0 s\tSHAPE : (4480, 256) (4480,)\n",
            "80 / 1872\t3.0 s\t614.0 s\tSHAPE : (5120, 256) (5120,)\n",
            "90 / 1872\t3.0 s\t610.0 s\tSHAPE : (5760, 256) (5760,)\n",
            "100 / 1872\t3.0 s\t606.0 s\tSHAPE : (6400, 256) (6400,)\n",
            "110 / 1872\t3.0 s\t605.0 s\tSHAPE : (7040, 256) (7040,)\n",
            "120 / 1872\t3.0 s\t601.0 s\tSHAPE : (7680, 256) (7680,)\n",
            "130 / 1872\t3.0 s\t599.0 s\tSHAPE : (8320, 256) (8320,)\n",
            "140 / 1872\t3.0 s\t596.0 s\tSHAPE : (8960, 256) (8960,)\n",
            "150 / 1872\t3.0 s\t593.0 s\tSHAPE : (9600, 256) (9600,)\n",
            "160 / 1872\t3.0 s\t589.0 s\tSHAPE : (10240, 256) (10240,)\n",
            "170 / 1872\t3.0 s\t586.0 s\tSHAPE : (10880, 256) (10880,)\n",
            "180 / 1872\t3.0 s\t585.0 s\tSHAPE : (11520, 256) (11520,)\n",
            "190 / 1872\t3.0 s\t580.0 s\tSHAPE : (12160, 256) (12160,)\n",
            "200 / 1872\t3.0 s\t576.0 s\tSHAPE : (12800, 256) (12800,)\n",
            "210 / 1872\t3.0 s\t574.0 s\tSHAPE : (13440, 256) (13440,)\n",
            "220 / 1872\t3.0 s\t571.0 s\tSHAPE : (14080, 256) (14080,)\n",
            "230 / 1872\t3.0 s\t567.0 s\tSHAPE : (14720, 256) (14720,)\n",
            "240 / 1872\t3.0 s\t564.0 s\tSHAPE : (15360, 256) (15360,)\n",
            "250 / 1872\t3.0 s\t562.0 s\tSHAPE : (16000, 256) (16000,)\n",
            "260 / 1872\t3.0 s\t560.0 s\tSHAPE : (16640, 256) (16640,)\n",
            "270 / 1872\t3.0 s\t556.0 s\tSHAPE : (17280, 256) (17280,)\n",
            "280 / 1872\t3.0 s\t551.0 s\tSHAPE : (17920, 256) (17920,)\n",
            "290 / 1872\t3.0 s\t552.0 s\tSHAPE : (18560, 256) (18560,)\n",
            "300 / 1872\t3.0 s\t546.0 s\tSHAPE : (19200, 256) (19200,)\n",
            "310 / 1872\t3.0 s\t542.0 s\tSHAPE : (19840, 256) (19840,)\n",
            "320 / 1872\t3.0 s\t541.0 s\tSHAPE : (20480, 256) (20480,)\n",
            "330 / 1872\t3.0 s\t535.0 s\tSHAPE : (21120, 256) (21120,)\n",
            "340 / 1872\t3.0 s\t533.0 s\tSHAPE : (21760, 256) (21760,)\n",
            "350 / 1872\t3.0 s\t530.0 s\tSHAPE : (22400, 256) (22400,)\n",
            "360 / 1872\t3.0 s\t526.0 s\tSHAPE : (23040, 256) (23040,)\n",
            "370 / 1872\t3.0 s\t522.0 s\tSHAPE : (23680, 256) (23680,)\n",
            "380 / 1872\t3.0 s\t521.0 s\tSHAPE : (24320, 256) (24320,)\n",
            "390 / 1872\t3.0 s\t516.0 s\tSHAPE : (24960, 256) (24960,)\n",
            "400 / 1872\t3.0 s\t513.0 s\tSHAPE : (25600, 256) (25600,)\n",
            "410 / 1872\t4.0 s\t512.0 s\tSHAPE : (26240, 256) (26240,)\n",
            "420 / 1872\t3.0 s\t506.0 s\tSHAPE : (26880, 256) (26880,)\n",
            "430 / 1872\t3.0 s\t502.0 s\tSHAPE : (27520, 256) (27520,)\n",
            "440 / 1872\t4.0 s\t502.0 s\tSHAPE : (28160, 256) (28160,)\n",
            "450 / 1872\t4.0 s\t498.0 s\tSHAPE : (28800, 256) (28800,)\n",
            "460 / 1872\t4.0 s\t495.0 s\tSHAPE : (29440, 256) (29440,)\n",
            "470 / 1872\t4.0 s\t491.0 s\tSHAPE : (30080, 256) (30080,)\n",
            "480 / 1872\t4.0 s\t488.0 s\tSHAPE : (30720, 256) (30720,)\n",
            "490 / 1872\t3.0 s\t479.0 s\tSHAPE : (31360, 256) (31360,)\n",
            "500 / 1872\t3.0 s\t476.0 s\tSHAPE : (32000, 256) (32000,)\n",
            "510 / 1872\t3.0 s\t475.0 s\tSHAPE : (32640, 256) (32640,)\n",
            "520 / 1872\t3.0 s\t469.0 s\tSHAPE : (33280, 256) (33280,)\n",
            "530 / 1872\t3.0 s\t465.0 s\tSHAPE : (33920, 256) (33920,)\n",
            "540 / 1872\t3.0 s\t465.0 s\tSHAPE : (34560, 256) (34560,)\n",
            "550 / 1872\t3.0 s\t460.0 s\tSHAPE : (35200, 256) (35200,)\n",
            "560 / 1872\t3.0 s\t457.0 s\tSHAPE : (35840, 256) (35840,)\n",
            "570 / 1872\t3.0 s\t455.0 s\tSHAPE : (36480, 256) (36480,)\n",
            "580 / 1872\t3.0 s\t450.0 s\tSHAPE : (37120, 256) (37120,)\n",
            "590 / 1872\t3.0 s\t446.0 s\tSHAPE : (37760, 256) (37760,)\n",
            "600 / 1872\t3.0 s\t445.0 s\tSHAPE : (38400, 256) (38400,)\n",
            "610 / 1872\t3.0 s\t441.0 s\tSHAPE : (39040, 256) (39040,)\n",
            "620 / 1872\t3.0 s\t436.0 s\tSHAPE : (39680, 256) (39680,)\n",
            "630 / 1872\t4.0 s\t435.0 s\tSHAPE : (40320, 256) (40320,)\n",
            "640 / 1872\t3.0 s\t431.0 s\tSHAPE : (40960, 256) (40960,)\n",
            "650 / 1872\t4.0 s\t467.0 s\tSHAPE : (41600, 256) (41600,)\n",
            "660 / 1872\t3.0 s\t424.0 s\tSHAPE : (42240, 256) (42240,)\n",
            "670 / 1872\t3.0 s\t421.0 s\tSHAPE : (42880, 256) (42880,)\n",
            "680 / 1872\t4.0 s\t418.0 s\tSHAPE : (43520, 256) (43520,)\n",
            "690 / 1872\t4.0 s\t415.0 s\tSHAPE : (44160, 256) (44160,)\n",
            "700 / 1872\t4.0 s\t414.0 s\tSHAPE : (44800, 256) (44800,)\n",
            "710 / 1872\t4.0 s\t411.0 s\tSHAPE : (45440, 256) (45440,)\n",
            "720 / 1872\t4.0 s\t407.0 s\tSHAPE : (46080, 256) (46080,)\n",
            "730 / 1872\t4.0 s\t402.0 s\tSHAPE : (46720, 256) (46720,)\n",
            "740 / 1872\t4.0 s\t399.0 s\tSHAPE : (47360, 256) (47360,)\n",
            "750 / 1872\t4.0 s\t395.0 s\tSHAPE : (48000, 256) (48000,)\n",
            "760 / 1872\t4.0 s\t393.0 s\tSHAPE : (48640, 256) (48640,)\n",
            "770 / 1872\t4.0 s\t389.0 s\tSHAPE : (49280, 256) (49280,)\n",
            "780 / 1872\t4.0 s\t386.0 s\tSHAPE : (49920, 256) (49920,)\n",
            "790 / 1872\t4.0 s\t384.0 s\tSHAPE : (50560, 256) (50560,)\n",
            "800 / 1872\t4.0 s\t380.0 s\tSHAPE : (51200, 256) (51200,)\n",
            "810 / 1872\t4.0 s\t376.0 s\tSHAPE : (51840, 256) (51840,)\n",
            "820 / 1872\t4.0 s\t372.0 s\tSHAPE : (52480, 256) (52480,)\n",
            "830 / 1872\t4.0 s\t370.0 s\tSHAPE : (53120, 256) (53120,)\n",
            "840 / 1872\t4.0 s\t364.0 s\tSHAPE : (53760, 256) (53760,)\n",
            "850 / 1872\t4.0 s\t362.0 s\tSHAPE : (54400, 256) (54400,)\n",
            "860 / 1872\t4.0 s\t357.0 s\tSHAPE : (55040, 256) (55040,)\n",
            "870 / 1872\t4.0 s\t354.0 s\tSHAPE : (55680, 256) (55680,)\n",
            "880 / 1872\t4.0 s\t353.0 s\tSHAPE : (56320, 256) (56320,)\n",
            "890 / 1872\t4.0 s\t352.0 s\tSHAPE : (56960, 256) (56960,)\n",
            "900 / 1872\t4.0 s\t345.0 s\tSHAPE : (57600, 256) (57600,)\n",
            "910 / 1872\t4.0 s\t342.0 s\tSHAPE : (58240, 256) (58240,)\n",
            "920 / 1872\t4.0 s\t339.0 s\tSHAPE : (58880, 256) (58880,)\n",
            "930 / 1872\t5.0 s\t496.0 s\tSHAPE : (59520, 256) (59520,)\n",
            "940 / 1872\t4.0 s\t332.0 s\tSHAPE : (60160, 256) (60160,)\n",
            "950 / 1872\t4.0 s\t329.0 s\tSHAPE : (60800, 256) (60800,)\n",
            "960 / 1872\t4.0 s\t325.0 s\tSHAPE : (61440, 256) (61440,)\n",
            "970 / 1872\t4.0 s\t322.0 s\tSHAPE : (62080, 256) (62080,)\n",
            "980 / 1872\t4.0 s\t319.0 s\tSHAPE : (62720, 256) (62720,)\n",
            "990 / 1872\t4.0 s\t315.0 s\tSHAPE : (63360, 256) (63360,)\n",
            "1000 / 1872\t4.0 s\t311.0 s\tSHAPE : (64000, 256) (64000,)\n",
            "1010 / 1872\t4.0 s\t309.0 s\tSHAPE : (64640, 256) (64640,)\n",
            "1020 / 1872\t4.0 s\t304.0 s\tSHAPE : (65280, 256) (65280,)\n",
            "1030 / 1872\t4.0 s\t300.0 s\tSHAPE : (65920, 256) (65920,)\n",
            "1040 / 1872\t4.0 s\t298.0 s\tSHAPE : (66560, 256) (66560,)\n",
            "1050 / 1872\t4.0 s\t293.0 s\tSHAPE : (67200, 256) (67200,)\n",
            "1060 / 1872\t4.0 s\t290.0 s\tSHAPE : (67840, 256) (67840,)\n",
            "1070 / 1872\t4.0 s\t287.0 s\tSHAPE : (68480, 256) (68480,)\n",
            "1080 / 1872\t4.0 s\t284.0 s\tSHAPE : (69120, 256) (69120,)\n",
            "1090 / 1872\t4.0 s\t281.0 s\tSHAPE : (69760, 256) (69760,)\n",
            "1100 / 1872\t4.0 s\t302.0 s\tSHAPE : (70400, 256) (70400,)\n",
            "1110 / 1872\t4.0 s\t274.0 s\tSHAPE : (71040, 256) (71040,)\n",
            "1120 / 1872\t4.0 s\t270.0 s\tSHAPE : (71680, 256) (71680,)\n",
            "1130 / 1872\t4.0 s\t268.0 s\tSHAPE : (72320, 256) (72320,)\n",
            "1140 / 1872\t4.0 s\t264.0 s\tSHAPE : (72960, 256) (72960,)\n",
            "1150 / 1872\t4.0 s\t259.0 s\tSHAPE : (73600, 256) (73600,)\n",
            "1160 / 1872\t4.0 s\t256.0 s\tSHAPE : (74240, 256) (74240,)\n",
            "1170 / 1872\t4.0 s\t252.0 s\tSHAPE : (74880, 256) (74880,)\n",
            "1180 / 1872\t4.0 s\t249.0 s\tSHAPE : (75520, 256) (75520,)\n",
            "1190 / 1872\t4.0 s\t247.0 s\tSHAPE : (76160, 256) (76160,)\n",
            "1200 / 1872\t4.0 s\t242.0 s\tSHAPE : (76800, 256) (76800,)\n",
            "1210 / 1872\t4.0 s\t239.0 s\tSHAPE : (77440, 256) (77440,)\n",
            "1220 / 1872\t4.0 s\t236.0 s\tSHAPE : (78080, 256) (78080,)\n",
            "1230 / 1872\t4.0 s\t233.0 s\tSHAPE : (78720, 256) (78720,)\n",
            "1240 / 1872\t4.0 s\t228.0 s\tSHAPE : (79360, 256) (79360,)\n",
            "1250 / 1872\t4.0 s\t225.0 s\tSHAPE : (80000, 256) (80000,)\n",
            "1260 / 1872\t4.0 s\t221.0 s\tSHAPE : (80640, 256) (80640,)\n",
            "1270 / 1872\t4.0 s\t218.0 s\tSHAPE : (81280, 256) (81280,)\n",
            "1280 / 1872\t4.0 s\t214.0 s\tSHAPE : (81920, 256) (81920,)\n",
            "1290 / 1872\t4.0 s\t212.0 s\tSHAPE : (82560, 256) (82560,)\n",
            "1300 / 1872\t4.0 s\t207.0 s\tSHAPE : (83200, 256) (83200,)\n",
            "1310 / 1872\t4.0 s\t204.0 s\tSHAPE : (83840, 256) (83840,)\n",
            "1320 / 1872\t4.0 s\t200.0 s\tSHAPE : (84480, 256) (84480,)\n",
            "1330 / 1872\t4.0 s\t197.0 s\tSHAPE : (85120, 256) (85120,)\n",
            "1340 / 1872\t4.0 s\t193.0 s\tSHAPE : (85760, 256) (85760,)\n",
            "1350 / 1872\t4.0 s\t190.0 s\tSHAPE : (86400, 256) (86400,)\n",
            "1360 / 1872\t4.0 s\t187.0 s\tSHAPE : (87040, 256) (87040,)\n",
            "1370 / 1872\t4.0 s\t183.0 s\tSHAPE : (87680, 256) (87680,)\n",
            "1380 / 1872\t4.0 s\t180.0 s\tSHAPE : (88320, 256) (88320,)\n",
            "1390 / 1872\t4.0 s\t176.0 s\tSHAPE : (88960, 256) (88960,)\n",
            "1400 / 1872\t4.0 s\t172.0 s\tSHAPE : (89600, 256) (89600,)\n",
            "1410 / 1872\t4.0 s\t169.0 s\tSHAPE : (90240, 256) (90240,)\n",
            "1420 / 1872\t4.0 s\t165.0 s\tSHAPE : (90880, 256) (90880,)\n",
            "1430 / 1872\t4.0 s\t161.0 s\tSHAPE : (91520, 256) (91520,)\n",
            "1440 / 1872\t4.0 s\t158.0 s\tSHAPE : (92160, 256) (92160,)\n",
            "1450 / 1872\t4.0 s\t154.0 s\tSHAPE : (92800, 256) (92800,)\n",
            "1460 / 1872\t4.0 s\t151.0 s\tSHAPE : (93440, 256) (93440,)\n",
            "1470 / 1872\t4.0 s\t148.0 s\tSHAPE : (94080, 256) (94080,)\n",
            "1480 / 1872\t4.0 s\t144.0 s\tSHAPE : (94720, 256) (94720,)\n",
            "1490 / 1872\t4.0 s\t140.0 s\tSHAPE : (95360, 256) (95360,)\n",
            "1500 / 1872\t4.0 s\t137.0 s\tSHAPE : (96000, 256) (96000,)\n",
            "1510 / 1872\t4.0 s\t133.0 s\tSHAPE : (96640, 256) (96640,)\n",
            "1520 / 1872\t4.0 s\t129.0 s\tSHAPE : (97280, 256) (97280,)\n",
            "1530 / 1872\t4.0 s\t126.0 s\tSHAPE : (97920, 256) (97920,)\n",
            "1540 / 1872\t4.0 s\t123.0 s\tSHAPE : (98560, 256) (98560,)\n",
            "1550 / 1872\t4.0 s\t118.0 s\tSHAPE : (99200, 256) (99200,)\n",
            "1560 / 1872\t4.0 s\t115.0 s\tSHAPE : (99840, 256) (99840,)\n",
            "1570 / 1872\t4.0 s\t111.0 s\tSHAPE : (100480, 256) (100480,)\n",
            "1580 / 1872\t4.0 s\t108.0 s\tSHAPE : (101120, 256) (101120,)\n",
            "1590 / 1872\t4.0 s\t104.0 s\tSHAPE : (101760, 256) (101760,)\n",
            "1600 / 1872\t4.0 s\t101.0 s\tSHAPE : (102400, 256) (102400,)\n",
            "1610 / 1872\t4.0 s\t96.0 s\tSHAPE : (103040, 256) (103040,)\n",
            "1620 / 1872\t4.0 s\t93.0 s\tSHAPE : (103680, 256) (103680,)\n",
            "1630 / 1872\t4.0 s\t90.0 s\tSHAPE : (104320, 256) (104320,)\n",
            "1640 / 1872\t4.0 s\t86.0 s\tSHAPE : (104960, 256) (104960,)\n",
            "1650 / 1872\t4.0 s\t82.0 s\tSHAPE : (105600, 256) (105600,)\n",
            "1660 / 1872\t4.0 s\t78.0 s\tSHAPE : (106240, 256) (106240,)\n",
            "1670 / 1872\t4.0 s\t75.0 s\tSHAPE : (106880, 256) (106880,)\n",
            "1680 / 1872\t4.0 s\t71.0 s\tSHAPE : (107520, 256) (107520,)\n",
            "1690 / 1872\t4.0 s\t68.0 s\tSHAPE : (108160, 256) (108160,)\n",
            "1700 / 1872\t4.0 s\t64.0 s\tSHAPE : (108800, 256) (108800,)\n",
            "1710 / 1872\t4.0 s\t60.0 s\tSHAPE : (109440, 256) (109440,)\n",
            "1720 / 1872\t4.0 s\t57.0 s\tSHAPE : (110080, 256) (110080,)\n",
            "1730 / 1872\t4.0 s\t53.0 s\tSHAPE : (110720, 256) (110720,)\n",
            "1740 / 1872\t4.0 s\t49.0 s\tSHAPE : (111360, 256) (111360,)\n",
            "1750 / 1872\t4.0 s\t45.0 s\tSHAPE : (112000, 256) (112000,)\n",
            "1760 / 1872\t4.0 s\t42.0 s\tSHAPE : (112640, 256) (112640,)\n",
            "1770 / 1872\t4.0 s\t38.0 s\tSHAPE : (113280, 256) (113280,)\n",
            "1780 / 1872\t4.0 s\t34.0 s\tSHAPE : (113920, 256) (113920,)\n",
            "1790 / 1872\t4.0 s\t31.0 s\tSHAPE : (114560, 256) (114560,)\n",
            "1800 / 1872\t4.0 s\t27.0 s\tSHAPE : (115200, 256) (115200,)\n",
            "1810 / 1872\t4.0 s\t23.0 s\tSHAPE : (115840, 256) (115840,)\n",
            "1820 / 1872\t4.0 s\t20.0 s\tSHAPE : (116480, 256) (116480,)\n",
            "1830 / 1872\t4.0 s\t16.0 s\tSHAPE : (117120, 256) (117120,)\n",
            "1840 / 1872\t4.0 s\t12.0 s\tSHAPE : (117760, 256) (117760,)\n",
            "1850 / 1872\t4.0 s\t9.0 s\tSHAPE : (118400, 256) (118400,)\n",
            "1860 / 1872\t4.0 s\t5.0 s\tSHAPE : (119040, 256) (119040,)\n",
            "1870 / 1872\t4.0 s\t1.0 s\tSHAPE : (119680, 256) (119680,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aVxlgTUKuFYi"
      },
      "source": [
        "import pickle\n",
        "with open(\"/content/drive/MyDrive/HateSpeech/ELECTRA_TRAIN2.pickle\",\"wb\") as f :\n",
        "  pickle.dump([temp,y_temp],f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IEgdRC84mk2S",
        "outputId": "549b0c33-9cea-4873-a4a3-79b960b41dc7"
      },
      "source": [
        "# save\n",
        "i=0\n",
        "start = time.time()\n",
        "for pred in val_dataset.batch(64):\n",
        "  if i%10==0 : \n",
        "    lef = len(df_val)/64\n",
        "    print(i,'/',int(lef),end='\\t')\n",
        "    ela = time.time()-start\n",
        "    print(round(ela,0),'s',end='\\t')\n",
        "    print(round(ela*(lef-i)/10,0),'s',end='\\t')\n",
        "    if i>0:print(\"SHAPE :\",temp.shape,y_temp.shape)\n",
        "    start = time.time()\n",
        "  if i == 0:\n",
        "    temp = model.predict(pred[0])[0][:,0,:]\n",
        "    y_temp = pred[1]\n",
        "    i+=1\n",
        "  else :\n",
        "    temp = np.append(temp,model.predict(pred[0])[0][:,0,:],axis=0)\n",
        "    y_temp = np.append(y_temp,pred[1])\n",
        "    i+=1\n",
        "with open(\"/content/drive/MyDrive/HateSpeech/ELECTRA_VAL2.pickle\",\"wb\") as f :\n",
        "  pickle.dump([temp,y_temp],f)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 / 467\t0.0 s\t2.0 s\t10 / 467\t3.0 s\t123.0 s\tSHAPE : (640, 256) (640,)\n",
            "20 / 467\t3.0 s\t121.0 s\tSHAPE : (1280, 256) (1280,)\n",
            "30 / 467\t3.0 s\t118.0 s\tSHAPE : (1920, 256) (1920,)\n",
            "40 / 467\t3.0 s\t120.0 s\tSHAPE : (2560, 256) (2560,)\n",
            "50 / 467\t3.0 s\t114.0 s\tSHAPE : (3200, 256) (3200,)\n",
            "60 / 467\t3.0 s\t111.0 s\tSHAPE : (3840, 256) (3840,)\n",
            "70 / 467\t3.0 s\t107.0 s\tSHAPE : (4480, 256) (4480,)\n",
            "80 / 467\t3.0 s\t104.0 s\tSHAPE : (5120, 256) (5120,)\n",
            "90 / 467\t3.0 s\t102.0 s\tSHAPE : (5760, 256) (5760,)\n",
            "100 / 467\t3.0 s\t99.0 s\tSHAPE : (6400, 256) (6400,)\n",
            "110 / 467\t3.0 s\t98.0 s\tSHAPE : (7040, 256) (7040,)\n",
            "120 / 467\t3.0 s\t95.0 s\tSHAPE : (7680, 256) (7680,)\n",
            "130 / 467\t3.0 s\t92.0 s\tSHAPE : (8320, 256) (8320,)\n",
            "140 / 467\t3.0 s\t89.0 s\tSHAPE : (8960, 256) (8960,)\n",
            "150 / 467\t3.0 s\t86.0 s\tSHAPE : (9600, 256) (9600,)\n",
            "160 / 467\t3.0 s\t84.0 s\tSHAPE : (10240, 256) (10240,)\n",
            "170 / 467\t3.0 s\t81.0 s\tSHAPE : (10880, 256) (10880,)\n",
            "180 / 467\t3.0 s\t79.0 s\tSHAPE : (11520, 256) (11520,)\n",
            "190 / 467\t3.0 s\t77.0 s\tSHAPE : (12160, 256) (12160,)\n",
            "200 / 467\t3.0 s\t74.0 s\tSHAPE : (12800, 256) (12800,)\n",
            "210 / 467\t3.0 s\t72.0 s\tSHAPE : (13440, 256) (13440,)\n",
            "220 / 467\t3.0 s\t69.0 s\tSHAPE : (14080, 256) (14080,)\n",
            "230 / 467\t3.0 s\t65.0 s\tSHAPE : (14720, 256) (14720,)\n",
            "240 / 467\t3.0 s\t62.0 s\tSHAPE : (15360, 256) (15360,)\n",
            "250 / 467\t3.0 s\t60.0 s\tSHAPE : (16000, 256) (16000,)\n",
            "260 / 467\t3.0 s\t57.0 s\tSHAPE : (16640, 256) (16640,)\n",
            "270 / 467\t3.0 s\t54.0 s\tSHAPE : (17280, 256) (17280,)\n",
            "280 / 467\t3.0 s\t52.0 s\tSHAPE : (17920, 256) (17920,)\n",
            "290 / 467\t3.0 s\t49.0 s\tSHAPE : (18560, 256) (18560,)\n",
            "300 / 467\t3.0 s\t46.0 s\tSHAPE : (19200, 256) (19200,)\n",
            "310 / 467\t3.0 s\t43.0 s\tSHAPE : (19840, 256) (19840,)\n",
            "320 / 467\t3.0 s\t41.0 s\tSHAPE : (20480, 256) (20480,)\n",
            "330 / 467\t3.0 s\t38.0 s\tSHAPE : (21120, 256) (21120,)\n",
            "340 / 467\t3.0 s\t35.0 s\tSHAPE : (21760, 256) (21760,)\n",
            "350 / 467\t3.0 s\t32.0 s\tSHAPE : (22400, 256) (22400,)\n",
            "360 / 467\t3.0 s\t29.0 s\tSHAPE : (23040, 256) (23040,)\n",
            "370 / 467\t3.0 s\t27.0 s\tSHAPE : (23680, 256) (23680,)\n",
            "380 / 467\t3.0 s\t24.0 s\tSHAPE : (24320, 256) (24320,)\n",
            "390 / 467\t3.0 s\t21.0 s\tSHAPE : (24960, 256) (24960,)\n",
            "400 / 467\t3.0 s\t19.0 s\tSHAPE : (25600, 256) (25600,)\n",
            "410 / 467\t3.0 s\t16.0 s\tSHAPE : (26240, 256) (26240,)\n",
            "420 / 467\t3.0 s\t13.0 s\tSHAPE : (26880, 256) (26880,)\n",
            "430 / 467\t4.0 s\t17.0 s\tSHAPE : (27520, 256) (27520,)\n",
            "440 / 467\t3.0 s\t8.0 s\tSHAPE : (28160, 256) (28160,)\n",
            "450 / 467\t3.0 s\t5.0 s\tSHAPE : (28800, 256) (28800,)\n",
            "460 / 467\t3.0 s\t2.0 s\tSHAPE : (29440, 256) (29440,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "lu7eJ9xWNuJ2",
        "outputId": "80a92fba-fb6d-4e22-aeae-e54472c75cfb"
      },
      "source": [
        "# save\n",
        "i=0\n",
        "start = time.time()\n",
        "for pred in test_dataset.batch(64):\n",
        "  if i%10==0 : \n",
        "    lef = len(df_test)/64\n",
        "    print(i,'/',int(lef),end='\\t')\n",
        "    ela = time.time()-start\n",
        "    print(round(ela,0),'s',end='\\t')\n",
        "    print(round(ela*(lef-i)/10,0),'s',end='\\t')\n",
        "    if i>0:print(\"SHAPE :\",temp.shape,y_temp.shape)\n",
        "    start = time.time()\n",
        "  if i == 0:\n",
        "    temp = model.predict(pred[0])[0][:,0,:]\n",
        "    y_temp = pred[1]\n",
        "    i+=1\n",
        "  else :\n",
        "    temp = np.append(temp,model.predict(pred[0])[0][:,0,:],axis=0)\n",
        "    y_temp = np.append(y_temp,pred[1])\n",
        "    i+=1\n",
        "with open(\"/content/drive/MyDrive/HateSpeech/ELECTRA_TEST2.pickle\",\"wb\") as f :\n",
        "  pickle.dump([temp,y_temp],f)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 / 239\t0.0 s\t0.0 s\t"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NotFittedError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-63dad626ee8c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0my_temp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mi\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    291\u001b[0m             \u001b[0mPredicted\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0mper\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m         \"\"\"\n\u001b[0;32m--> 293\u001b[0;31m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py\u001b[0m in \u001b[0;36mdecision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    264\u001b[0m             \u001b[0;32mclass\u001b[0m \u001b[0mwould\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mpredicted\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m         \"\"\"\n\u001b[0;32m--> 266\u001b[0;31m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_is_fitted\u001b[0;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[1;32m    965\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 967\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    968\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    969\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotFittedError\u001b[0m: This LogisticRegression instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6LS7Gf_yqNoO"
      },
      "source": [
        "### LOAD EMBEDDED DATASET"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7rU4YMr65ve"
      },
      "source": [
        "# load\n",
        "import pickle\n",
        "with open(\"/content/drive/MyDrive/HateSpeech/test.pickle\",\"rb\") as f :\n",
        "  test_hs = pickle.load(f)\n",
        "with open(\"/content/drive/MyDrive/HateSpeech/val.pickle\",\"rb\") as f :\n",
        "  val_hs = pickle.load(f)\n",
        "with open(\"/content/drive/MyDrive/HateSpeech/train.pickle\",\"rb\") as f :\n",
        "  train_hs = pickle.load(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7lLG4Z1NfEe"
      },
      "source": [
        "with open(\"/content/drive/MyDrive/HateSpeech/ELECTRA_TRAIN2.pickle\",\"rb\") as f :\n",
        "  train_hs = pickle.load(f)\n",
        "with open(\"/content/drive/MyDrive/HateSpeech/ELECTRA_VAL2.pickle\",\"rb\") as f :\n",
        "  val_hs = pickle.load(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VsA7yZASobCl",
        "outputId": "776c1a4b-06ad-4196-fa7a-b559a4005f52"
      },
      "source": [
        "for hs in [train_hs,val_hs]:\n",
        "  print(hs[0].shape,hs[1].shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(119868, 256) (119868,)\n",
            "(29931, 256) (29931,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tp1FfcLRf3kb",
        "outputId": "300a9dcf-8db8-4e9a-e5e9-1eef31aeccbc"
      },
      "source": [
        "119868+29931"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "149799"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_QUpJeMSUBkP"
      },
      "source": [
        "## MachinLearning Fit & Evaluate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OtyFm1Zhur81"
      },
      "source": [
        "### Logistic,RF,LGBM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9E5fJc50QL5B",
        "outputId": "b9b7fb3e-1f7f-477e-ac6d-433a0dc61ae4"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "model_list = []\n",
        "model_list.append([LogisticRegression(),'LogisticRegression'])\n",
        "model_list.append([RandomForestClassifier(max_depth=None,min_samples_split=4,n_estimators=100,oob_score=False,n_jobs=-1,verbose=10),\n",
        "                  'RandomForestClassifier'])\n",
        "model_list.append([LGBMClassifier(),'LGBMClassifier'])\n",
        "model_list"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                     intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                     multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                     random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                     warm_start=False), 'LogisticRegression'],\n",
              " [RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                         criterion='gini', max_depth=None, max_features='auto',\n",
              "                         max_leaf_nodes=None, max_samples=None,\n",
              "                         min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                         min_samples_leaf=1, min_samples_split=4,\n",
              "                         min_weight_fraction_leaf=0.0, n_estimators=100,\n",
              "                         n_jobs=-1, oob_score=False, random_state=None,\n",
              "                         verbose=10, warm_start=False),\n",
              "  'RandomForestClassifier'],\n",
              " [LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
              "                 importance_type='split', learning_rate=0.1, max_depth=-1,\n",
              "                 min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
              "                 n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,\n",
              "                 random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
              "                 subsample=1.0, subsample_for_bin=200000, subsample_freq=0),\n",
              "  'LGBMClassifier']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PFBj6SvUu46E"
      },
      "source": [
        "### Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ppTRiovVo8W8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "outputId": "90748d8e-e933-4194-fc6a-577d354dfd04"
      },
      "source": [
        "eval = pd.DataFrame([[np.nan for i in range(11)]])\n",
        "eval.columns = ['Model',\n",
        "                'Train_Score(ACC)','Train_Score(ROC_AUC)','Train_Score(F1)',\n",
        "                'Val_Score(ACC)','Val_Score(ROC_AUC)','Val_Score(F1)',\n",
        "                'Test_Score(ACC)','Test_Score(ROC_AUC)','Test_Score(F1)','Inference_Time']\n",
        "eval = eval.iloc[1:]\n",
        "\n",
        "for model, model_name in model_list:\n",
        "  data_start = time.time()\n",
        "  X_train = train_hs[0]\n",
        "  y_train = train_hs[1]\n",
        "  X_val = val_hs[0]\n",
        "  y_val = val_hs[1]\n",
        "  X_test = test_hs[0]\n",
        "  y_test = test_hs[1]\n",
        "  # Fit\n",
        "  LR = model\n",
        "  LR.fit(X_train,y_train)\n",
        "\n",
        "  # Inference\n",
        "  print(\"TRAIN SET\")\n",
        "  fitted = LR.predict(X_train)\n",
        "  fitted_proba = LR.predict_proba(X_train)\n",
        "\n",
        "  print(\"VAL SET\")\n",
        "  val_pred = LR.predict(X_val)\n",
        "  val_pred_proba = LR.predict_proba(X_val)\n",
        "\n",
        "  print(\"TEST SET\")\n",
        "  start = time.time()\n",
        "  test_pred = LR.predict(X_test)\n",
        "  inference_time = time.time()-start\n",
        "  test_pred_proba = LR.predict_proba(X_test)\n",
        "  print(f\"Inferenced : {inference_time}s\",end='\\t')\n",
        "\n",
        "  # Evaluate\n",
        "  train_acc = accuracy_score(y_train,fitted)\n",
        "  train_auc = roc_auc_score(y_train,fitted_proba[:,1])\n",
        "  train_f1 = f1_score(y_train,fitted)\n",
        "\n",
        "  val_acc = accuracy_score(y_val,val_pred)\n",
        "  val_auc = roc_auc_score(y_val,val_pred_proba[:,1])\n",
        "  val_f1 = f1_score(y_val,val_pred)\n",
        "\n",
        "  test_acc = accuracy_score(y_test,test_pred)\n",
        "  test_auc = roc_auc_score(y_test,test_pred_proba[:,1])\n",
        "  test_f1 = f1_score(y_test,test_pred)\n",
        "  print(f\"train ROCAUC : {train_auc} val ROCAUC : {val_auc} test ROCAUC : {test_auc} \")\n",
        "\n",
        "  LR_list = [model_name]\n",
        "  LR_list.append(train_acc)\n",
        "  LR_list.append(train_auc)\n",
        "  LR_list.append(train_f1)\n",
        "  LR_list.append(val_acc)\n",
        "  LR_list.append(val_auc)\n",
        "  LR_list.append(val_f1)\n",
        "  LR_list.append(test_acc)\n",
        "  LR_list.append(test_auc)\n",
        "  LR_list.append(test_f1)\n",
        "  LR_list.append(inference_time)\n",
        "\n",
        "  eval = eval.append(pd.DataFrame([LR_list],columns=eval.columns))\n",
        "  print(f\"{time.time()-data_start}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-96e268c454f8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0mX_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_hs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m   \u001b[0my_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_hs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m   \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_hs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m   \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_hs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m   \u001b[0;31m# Fit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'test_hs' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "id": "Ik5F5nEVruT5",
        "outputId": "de698b52-b9ea-460f-c027-af25ef9cd923"
      },
      "source": [
        "eval"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Train_Score(ACC)</th>\n",
              "      <th>Train_Score(ROC_AUC)</th>\n",
              "      <th>Train_Score(F1)</th>\n",
              "      <th>Val_Score(ACC)</th>\n",
              "      <th>Val_Score(ROC_AUC)</th>\n",
              "      <th>Val_Score(F1)</th>\n",
              "      <th>Test_Score(ACC)</th>\n",
              "      <th>Test_Score(ROC_AUC)</th>\n",
              "      <th>Test_Score(F1)</th>\n",
              "      <th>Inference_Time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>LogisticRegression_BERT_EMBED</td>\n",
              "      <td>0.842627</td>\n",
              "      <td>0.921017</td>\n",
              "      <td>0.845100</td>\n",
              "      <td>0.842371</td>\n",
              "      <td>0.920272</td>\n",
              "      <td>0.844208</td>\n",
              "      <td>0.360042</td>\n",
              "      <td>0.502175</td>\n",
              "      <td>0.383998</td>\n",
              "      <td>0.048613</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>RandomForestClassifier_BERT_EMBED</td>\n",
              "      <td>0.998974</td>\n",
              "      <td>0.999996</td>\n",
              "      <td>0.998990</td>\n",
              "      <td>0.823527</td>\n",
              "      <td>0.903100</td>\n",
              "      <td>0.824437</td>\n",
              "      <td>0.405641</td>\n",
              "      <td>0.499277</td>\n",
              "      <td>0.376691</td>\n",
              "      <td>0.123162</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>LGBMClassifier_BERT_EMBED</td>\n",
              "      <td>0.855266</td>\n",
              "      <td>0.933154</td>\n",
              "      <td>0.857789</td>\n",
              "      <td>0.834887</td>\n",
              "      <td>0.915230</td>\n",
              "      <td>0.836876</td>\n",
              "      <td>0.379910</td>\n",
              "      <td>0.499551</td>\n",
              "      <td>0.382324</td>\n",
              "      <td>0.016189</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                               Model  ...  Inference_Time\n",
              "0      LogisticRegression_BERT_EMBED  ...        0.048613\n",
              "0  RandomForestClassifier_BERT_EMBED  ...        0.123162\n",
              "0          LGBMClassifier_BERT_EMBED  ...        0.016189\n",
              "\n",
              "[3 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2ftfwjkp7C3"
      },
      "source": [
        "eval.to_csv(f\"/content/drive/MyDrive/HateSpeech/PERFORMANCE2/ML_BERT.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m0H0E5fM6rTU"
      },
      "source": [
        "# 3 Build Bert Embedded Dataset (SqueezeBERT)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WNjF8Jw4Pw80"
      },
      "source": [
        "## BERT TOKENIZER"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 288,
          "referenced_widgets": [
            "dbc87d4ddb864afeac0883ea0042166e",
            "b72028fdea4c4167b47652dced522441",
            "4b09b153e65a47e5beb94bfb4b7841df",
            "7208c750014f4ca2ba3f513326023dcf",
            "31b26f36f56f44ca8c9af52f355c70a2",
            "b6d5be63d50f463cbb4ae94704ee6dc2",
            "db962db78f59452bbfc1edd4938a5b16",
            "d391dc79b01a41cda0faef8e6915c629",
            "518522089a0b4391ae33bcb4f50cd1f2",
            "f48f6eb020124bb0b106566a8133bb92",
            "0f81759bb35340638d7f7be0bd4b3455",
            "b5235cd9ae0c44ef9bb9eecc29d97f74",
            "508e78db52084cc9ae8b61b68e57f3a1",
            "3a98e12163d04b00bb055291b10f05bd",
            "e98c59b787dd45b0a840de4d52cb4bb1",
            "37e827aa64bd4ab7b03dbd718f36fdc9",
            "cf26d4181bfb4500b8dff410842eb4df",
            "873dc06a32e0438ca0f495475cffbdb1",
            "0107964b116a4a0486683bac33e5c8de",
            "06f712a47d194f5bab9fc52cd4a53e82",
            "38a445396068498da2dc87e5c3dc1ed6",
            "9cc6459b00f846518e46a83872a43008",
            "7aab0542f7ed49088eb3f07c4b259f03",
            "c1c4f7f30ca44cfa8bc44ef4d0dfb7fd",
            "4eea3f15f3e947ce964349ab92a826f9",
            "eebe3ca29c1540b5b1f6c0d8f5ee28fd",
            "bae7d4988d2645f1bd24fcebea64cf88",
            "815d80e2a1f347e68ff6f2f953be68d6",
            "98dcd8712c3a4b29a08145a318844634",
            "bc64b6f2ba3046d9a720c0974d192d0d",
            "8595be04032445c1bbe014472fa47cfd",
            "59211b77d2ca4f09a6cb9dcde796c7e1"
          ]
        },
        "id": "0BSBW3kz6v2F",
        "outputId": "7b8ecadf-26be-42d9-c77a-c8e50efb72ed"
      },
      "source": [
        "from transformers import AutoTokenizer, AutoModel\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"squeezebert/squeezebert-uncased\")\n",
        "model = AutoModel.from_pretrained(\"squeezebert/squeezebert-uncased\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dbc87d4ddb864afeac0883ea0042166e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=500.0, style=ProgressStyle(description_â€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "518522089a0b4391ae33bcb4f50cd1f2",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231580.0, style=ProgressStyle(descriptiâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cf26d4181bfb4500b8dff410842eb4df",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=466182.0, style=ProgressStyle(descriptiâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4eea3f15f3e947ce964349ab92a826f9",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=103473649.0, style=ProgressStyle(descriâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at squeezebert/squeezebert-uncased were not used when initializing SqueezeBertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing SqueezeBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing SqueezeBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4qddtfq_QJbw"
      },
      "source": [
        "### BUILD DATASET"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tby52Qh261No",
        "outputId": "39183ee3-6dd9-4a87-be1c-bb0091763b58"
      },
      "source": [
        "import time\n",
        "\n",
        "X_train = df_train['text'].to_list()\n",
        "y_train = df_train['class'].to_list()\n",
        "X_val = df_val['text'].to_list()\n",
        "y_val = df_val['class'].to_list()\n",
        "X_test = df_test['text'].to_list()\n",
        "y_test = df_test['class'].to_list()\n",
        "\n",
        "# Tokenizing\n",
        "encoding_time = time.time()\n",
        "train_encodings = tokenizer(X_train, truncation=True, padding=True)\n",
        "val_encodings = tokenizer(X_val, truncation=True, padding=True)\n",
        "test_encodings = tokenizer(X_test, truncation=True, padding=True)\n",
        "print(\"encoding time : \", time.time()-encoding_time)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "encoding time :  42.50465726852417\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qxSDU5mE69Ql",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01b22f13-b0d2-4bb5-bb41-afb0b0f31bf0"
      },
      "source": [
        "# Build Dataset\n",
        "dataset_time = time.time()\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((\n",
        "    dict(train_encodings),\n",
        "    y_train\n",
        "))\n",
        "print(\"building dataset : \", time.time()-dataset_time)\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((\n",
        "    dict(val_encodings),\n",
        "    y_val\n",
        "))\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((\n",
        "    dict(test_encodings),\n",
        "    y_test\n",
        "))\n",
        "print(\"building dataset : \", time.time()-dataset_time)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "building dataset :  418.4919927120209\n",
            "building dataset :  506.6187915802002\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CpbMvZueQMU_"
      },
      "source": [
        "## EMBEDDING"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i3ZI-587Oaau"
      },
      "source": [
        "### SAVE EMBEDDED DATASET"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H0csdedP7TAe"
      },
      "source": [
        "import torch\n",
        "\n",
        "# save\n",
        "i=0\n",
        "start = time.time()\n",
        "for pred in train_dataset.batch(64):\n",
        "  if i%10==0 : \n",
        "    lef = len(df_train)/64\n",
        "    print(i,'/',int(lef),end='\\t')\n",
        "    ela = time.time()-start\n",
        "    print(round(ela,0),'s',end='\\t')\n",
        "    print(round(ela*(lef-i)/10,0),'s',end='\\t')\n",
        "    if i>0: print(\"SHAPE :\",temp.shape,y_temp.shape)\n",
        "    start = time.time()\n",
        "  if i == 0:\n",
        "    with torch.no_grad():\n",
        "        temp = model(torch.tensor(np.array(pred[0]['input_ids'])))[0][:,0,:]\n",
        "    y_temp = pred[1]\n",
        "    i+=1\n",
        "  else :\n",
        "    with torch.no_grad():\n",
        "        temp_input = model(torch.tensor(np.array(pred[0]['input_ids'])))[0][:,0,:]\n",
        "    temp = np.append(temp,temp_input,axis=0)\n",
        "    y_temp = np.append(y_temp,pred[1])\n",
        "    i+=1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3sku_gwxwYYu"
      },
      "source": [
        "import pickle\n",
        "with open(\"/content/drive/MyDrive/HateSpeech/train_squeeze.pickle\",\"wb\") as f :\n",
        "  pickle.dump([temp,y_temp],f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xKUcCPWCxA7e"
      },
      "source": [
        "import torch\n",
        "\n",
        "# save\n",
        "start = time.time()\n",
        "for ds in [[val_dataset,'val'],[test_dataset,'test']]:\n",
        "  i=0\n",
        "  for pred in ds[0].batch(64):\n",
        "    if i%10==0 : \n",
        "      lef = len(df_train)/64\n",
        "      print(i,'/',int(lef),end='\\t')\n",
        "      ela = time.time()-start\n",
        "      print(round(ela,0),'s',end='\\t')\n",
        "      print(round(ela*(lef-i)/10,0),'s',end='\\t')\n",
        "      if i>0: print(\"SHAPE :\",temp.shape,y_temp.shape)\n",
        "      start = time.time()\n",
        "    if i == 0:\n",
        "      with torch.no_grad():\n",
        "          temp = model(torch.tensor(np.array(pred[0]['input_ids'])))[0][:,0,:]\n",
        "      y_temp = pred[1]\n",
        "      i+=1\n",
        "    else :\n",
        "      with torch.no_grad():\n",
        "          temp_input = model(torch.tensor(np.array(pred[0]['input_ids'])))[0][:,0,:]\n",
        "      temp = np.append(temp,temp_input,axis=0)\n",
        "      y_temp = np.append(y_temp,pred[1])\n",
        "      i+=1\n",
        "  with open(f\"/content/drive/MyDrive/HateSpeech/{ds[1]}_squeeze.pickle\",\"wb\") as f :\n",
        "    pickle.dump([temp,y_temp],f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nymmRDffOeZ2"
      },
      "source": [
        "### LOAD EMBEDDED DATASET"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vj9VQRPiOgfe"
      },
      "source": [
        "# load\n",
        "import pickle\n",
        "with open(\"/content/drive/MyDrive/HateSpeech/test.pickle\",\"rb\") as f :\n",
        "  test_hs = pickle.load(f)\n",
        "with open(\"/content/drive/MyDrive/HateSpeech/val.pickle\",\"rb\") as f :\n",
        "  val_hs = pickle.load(f)\n",
        "with open(\"/content/drive/MyDrive/HateSpeech/train.pickle\",\"rb\") as f :\n",
        "  train_hs = pickle.load(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ywkw_HRAQl4_"
      },
      "source": [
        "## MachinLearning Fit & Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2s7KKsRBQnCo",
        "outputId": "cc212184-a1af-4bae-d04a-6511c24d7094"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "model_list = []\n",
        "model_list.append([LogisticRegression(),'LogisticRegression'])\n",
        "model_list.append([RandomForestClassifier(max_depth=None,min_samples_split=4,n_estimators=100,oob_score=False,n_jobs=-1,verbose=10),\n",
        "                  'RandomForestClassifier'])\n",
        "model_list.append([LGBMClassifier(),'LGBMClassifier'])\n",
        "model_list"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                     intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                     multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                     random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                     warm_start=False), 'LogisticRegression'],\n",
              " [RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                         criterion='gini', max_depth=None, max_features='auto',\n",
              "                         max_leaf_nodes=None, max_samples=None,\n",
              "                         min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                         min_samples_leaf=1, min_samples_split=4,\n",
              "                         min_weight_fraction_leaf=0.0, n_estimators=100,\n",
              "                         n_jobs=-1, oob_score=False, random_state=None,\n",
              "                         verbose=10, warm_start=False),\n",
              "  'RandomForestClassifier'],\n",
              " [LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
              "                 importance_type='split', learning_rate=0.1, max_depth=-1,\n",
              "                 min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
              "                 n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,\n",
              "                 random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
              "                 subsample=1.0, subsample_for_bin=200000, subsample_freq=0),\n",
              "  'LGBMClassifier']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rXvkFJV2QqlE",
        "outputId": "7b8e58ca-e6e2-4a7c-c7dc-25ce69d8240d"
      },
      "source": [
        "eval = pd.DataFrame([[np.nan for i in range(11)]])\n",
        "eval.columns = ['Model',\n",
        "                'Train_Score(ACC)','Train_Score(ROC_AUC)','Train_Score(F1)',\n",
        "                'Val_Score(ACC)','Val_Score(ROC_AUC)','Val_Score(F1)',\n",
        "                'Test_Score(ACC)','Test_Score(ROC_AUC)','Test_Score(F1)','Inference_Time']\n",
        "eval = eval.iloc[1:]\n",
        "\n",
        "for model, model_name in model_list:\n",
        "  data_start = time.time()\n",
        "  X_train = train_hs[0]\n",
        "  y_train = train_hs[1]\n",
        "  X_val = val_hs[0]\n",
        "  y_val = val_hs[1]\n",
        "  # X_test = test_hs[0]\n",
        "  # y_test = test_hs[1]\n",
        "  # Fit\n",
        "  LR = model\n",
        "  LR.fit(X_train,y_train)\n",
        "\n",
        "  # Inference\n",
        "  print(\"TRAIN SET\")\n",
        "  fitted = LR.predict(X_train)\n",
        "  fitted_proba = LR.predict_proba(X_train)\n",
        "\n",
        "  print(\"VAL SET\")\n",
        "  val_pred = LR.predict(X_val)\n",
        "  val_pred_proba = LR.predict_proba(X_val)\n",
        "\n",
        "  # print(\"TEST SET\")\n",
        "  # start = time.time()\n",
        "  # test_pred = LR.predict(X_test)\n",
        "  # inference_time = time.time()-start\n",
        "  # test_pred_proba = LR.predict_proba(X_test)\n",
        "  # print(f\"Inferenced : {inference_time}s\",end='\\t')\n",
        "\n",
        "  # Evaluate\n",
        "  train_acc = accuracy_score(y_train,fitted)\n",
        "  train_auc = roc_auc_score(y_train,fitted_proba[:,1])\n",
        "  train_f1 = f1_score(y_train,fitted)\n",
        "\n",
        "  val_acc = accuracy_score(y_val,val_pred)\n",
        "  val_auc = roc_auc_score(y_val,val_pred_proba[:,1])\n",
        "  val_f1 = f1_score(y_val,val_pred)\n",
        "\n",
        "  # test_acc = accuracy_score(y_test,test_pred)\n",
        "  # test_auc = roc_auc_score(y_test,test_pred_proba[:,1])\n",
        "  # test_f1 = f1_score(y_test,test_pred)\n",
        "  print(f\"train ROCAUC : {train_auc} val ROCAUC : {val_auc} test ROCAUC :  \")\n",
        "  LR_list = [model_name+\"_ELECTRA\"]\n",
        "  LR_list.append(train_acc)\n",
        "  LR_list.append(train_auc)\n",
        "  LR_list.append(train_f1)\n",
        "  LR_list.append(val_acc)\n",
        "  LR_list.append(val_auc)\n",
        "  LR_list.append(val_f1)\n",
        "  LR_list.append(0)\n",
        "  LR_list.append(0)\n",
        "  LR_list.append(0)\n",
        "  LR_list.append(0)\n",
        "\n",
        "  filename = f'/content/drive/MyDrive/HateSpeech/Weight/ML/{model_name}_electra.sav'\n",
        "  pickle.dump(LR, open(filename, 'wb'))\n",
        "  eval = eval.append(pd.DataFrame([LR_list],columns=eval.columns))\n",
        "  print(f\"{time.time()-data_start}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TRAIN SET\n",
            "VAL SET\n",
            "train ROCAUC : 0.9711075531942035 val ROCAUC : 0.9624789457679603 test ROCAUC :  \n",
            "4.3477537631988525\n",
            "building tree 1 of 100\n",
            "building tree 2 of 100\n",
            "building tree 3 of 100\n",
            "building tree 4 of 100\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "building tree 5 of 100\n",
            "building tree 6 of 100\n",
            "building tree 7 of 100\n",
            "building tree 8 of 100\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    9.1s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "building tree 9 of 100\n",
            "building tree 10 of 100\n",
            "building tree 11 of 100\n",
            "building tree 12 of 100\n",
            "building tree 13 of 100\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:   14.2s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "building tree 14 of 100\n",
            "building tree 15 of 100\n",
            "building tree 16 of 100\n",
            "building tree 17 of 100\n",
            "building tree 18 of 100\n",
            "building tree 19 of 100\n",
            "building tree 20 of 100\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:   22.8s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "building tree 21 of 100\n",
            "building tree 22 of 100\n",
            "building tree 23 of 100\n",
            "building tree 24 of 100\n",
            "building tree 25 of 100\n",
            "building tree 26 of 100\n",
            "building tree 27 of 100\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:   28.9s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "building tree 28 of 100\n",
            "building tree 29 of 100\n",
            "building tree 30 of 100\n",
            "building tree 31 of 100\n",
            "building tree 32 of 100\n",
            "building tree 33 of 100\n",
            "building tree 34 of 100\n",
            "building tree 35 of 100\n",
            "building tree 36 of 100\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   41.5s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "building tree 37 of 100\n",
            "building tree 38 of 100\n",
            "building tree 39 of 100\n",
            "building tree 40 of 100\n",
            "building tree 41 of 100\n",
            "building tree 42 of 100\n",
            "building tree 43 of 100\n",
            "building tree 44 of 100\n",
            "building tree 45 of 100\n",
            "building tree 46 of 100\n",
            "building tree 47 of 100\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   51.7s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "building tree 48 of 100\n",
            "building tree 49 of 100\n",
            "building tree 50 of 100\n",
            "building tree 51 of 100\n",
            "building tree 52 of 100\n",
            "building tree 53 of 100\n",
            "building tree 54 of 100\n",
            "building tree 55 of 100\n",
            "building tree 56 of 100\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed:  1.1min\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "building tree 57 of 100\n",
            "building tree 58 of 100\n",
            "building tree 59 of 100\n",
            "building tree 60 of 100\n",
            "building tree 61 of 100\n",
            "building tree 62 of 100\n",
            "building tree 63 of 100\n",
            "building tree 64 of 100\n",
            "building tree 65 of 100\n",
            "building tree 66 of 100\n",
            "building tree 67 of 100\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:  1.3min\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "building tree 68 of 100\n",
            "building tree 69 of 100\n",
            "building tree 70 of 100\n",
            "building tree 71 of 100\n",
            "building tree 72 of 100\n",
            "building tree 73 of 100\n",
            "building tree 74 of 100\n",
            "building tree 75 of 100\n",
            "building tree 76 of 100\n",
            "building tree 77 of 100\n",
            "building tree 78 of 100\n",
            "building tree 79 of 100\n",
            "building tree 80 of 100\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done  77 tasks      | elapsed:  1.6min\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "building tree 81 of 100\n",
            "building tree 82 of 100\n",
            "building tree 83 of 100\n",
            "building tree 84 of 100\n",
            "building tree 85 of 100\n",
            "building tree 86 of 100\n",
            "building tree 87 of 100\n",
            "building tree 88 of 100\n",
            "building tree 89 of 100\n",
            "building tree 90 of 100\n",
            "building tree 91 of 100\n",
            "building tree 92 of 100\n",
            "building tree 93 of 100\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done  90 tasks      | elapsed:  1.8min\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "building tree 94 of 100\n",
            "building tree 95 of 100\n",
            "building tree 96 of 100\n",
            "building tree 97 of 100\n",
            "building tree 98 of 100\n",
            "building tree 99 of 100\n",
            "building tree 100 of 100\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  2.0min finished\n",
            "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
            "[Parallel(n_jobs=4)]: Done   5 tasks      | elapsed:    0.1s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "TRAIN SET\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=4)]: Done  10 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=4)]: Done  17 tasks      | elapsed:    0.2s\n",
            "[Parallel(n_jobs=4)]: Done  24 tasks      | elapsed:    0.3s\n",
            "[Parallel(n_jobs=4)]: Done  33 tasks      | elapsed:    0.4s\n",
            "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.5s\n",
            "[Parallel(n_jobs=4)]: Done  53 tasks      | elapsed:    0.6s\n",
            "[Parallel(n_jobs=4)]: Done  64 tasks      | elapsed:    0.7s\n",
            "[Parallel(n_jobs=4)]: Done  77 tasks      | elapsed:    0.9s\n",
            "[Parallel(n_jobs=4)]: Done  90 tasks      | elapsed:    1.0s\n",
            "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    1.1s finished\n",
            "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
            "[Parallel(n_jobs=4)]: Done   5 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=4)]: Done  10 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=4)]: Done  17 tasks      | elapsed:    0.2s\n",
            "[Parallel(n_jobs=4)]: Done  24 tasks      | elapsed:    0.3s\n",
            "[Parallel(n_jobs=4)]: Done  33 tasks      | elapsed:    0.4s\n",
            "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.5s\n",
            "[Parallel(n_jobs=4)]: Done  53 tasks      | elapsed:    0.6s\n",
            "[Parallel(n_jobs=4)]: Done  64 tasks      | elapsed:    0.7s\n",
            "[Parallel(n_jobs=4)]: Done  77 tasks      | elapsed:    0.8s\n",
            "[Parallel(n_jobs=4)]: Done  90 tasks      | elapsed:    1.0s\n",
            "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    1.1s finished\n",
            "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
            "[Parallel(n_jobs=4)]: Done   5 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=4)]: Done  10 tasks      | elapsed:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "VAL SET\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=4)]: Done  17 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=4)]: Done  24 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=4)]: Done  33 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=4)]: Done  53 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=4)]: Done  64 tasks      | elapsed:    0.2s\n",
            "[Parallel(n_jobs=4)]: Done  77 tasks      | elapsed:    0.2s\n",
            "[Parallel(n_jobs=4)]: Done  90 tasks      | elapsed:    0.2s\n",
            "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.3s finished\n",
            "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
            "[Parallel(n_jobs=4)]: Done   5 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=4)]: Done  10 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=4)]: Done  17 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=4)]: Done  24 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=4)]: Done  33 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=4)]: Done  53 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=4)]: Done  64 tasks      | elapsed:    0.2s\n",
            "[Parallel(n_jobs=4)]: Done  77 tasks      | elapsed:    0.2s\n",
            "[Parallel(n_jobs=4)]: Done  90 tasks      | elapsed:    0.2s\n",
            "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.2s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train ROCAUC : 0.9999838168286036 val ROCAUC : 0.9604219604164584 test ROCAUC :  \n",
            "123.03383088111877\n",
            "TRAIN SET\n",
            "VAL SET\n",
            "train ROCAUC : 0.9788533738482479 val ROCAUC : 0.9625013023869374 test ROCAUC :  \n",
            "14.636789083480835\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        },
        "id": "h670PZuyRYWz",
        "outputId": "e8d9dc08-66bc-4e33-9431-0f6134191ab2"
      },
      "source": [
        "eval"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Train_Score(ACC)</th>\n",
              "      <th>Train_Score(ROC_AUC)</th>\n",
              "      <th>Train_Score(F1)</th>\n",
              "      <th>Val_Score(ACC)</th>\n",
              "      <th>Val_Score(ROC_AUC)</th>\n",
              "      <th>Val_Score(F1)</th>\n",
              "      <th>Test_Score(ACC)</th>\n",
              "      <th>Test_Score(ROC_AUC)</th>\n",
              "      <th>Test_Score(F1)</th>\n",
              "      <th>Inference_Time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>LogisticRegression_ELECTRA</td>\n",
              "      <td>0.910819</td>\n",
              "      <td>0.971108</td>\n",
              "      <td>0.912469</td>\n",
              "      <td>0.894725</td>\n",
              "      <td>0.962479</td>\n",
              "      <td>0.896427</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>RandomForestClassifier_ELECTRA</td>\n",
              "      <td>0.998231</td>\n",
              "      <td>0.999984</td>\n",
              "      <td>0.998259</td>\n",
              "      <td>0.895326</td>\n",
              "      <td>0.960422</td>\n",
              "      <td>0.896863</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>LGBMClassifier_ELECTRA</td>\n",
              "      <td>0.917626</td>\n",
              "      <td>0.978853</td>\n",
              "      <td>0.919145</td>\n",
              "      <td>0.896328</td>\n",
              "      <td>0.962501</td>\n",
              "      <td>0.897978</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                            Model  ...  Inference_Time\n",
              "0      LogisticRegression_ELECTRA  ...             0.0\n",
              "0  RandomForestClassifier_ELECTRA  ...             0.0\n",
              "0          LGBMClassifier_ELECTRA  ...             0.0\n",
              "\n",
              "[3 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MnGOyMn5ReA_"
      },
      "source": [
        "eval.to_csv(f\"/content/drive/MyDrive/HateSpeech/PERFORMANCE2/ML_ELELECTRA.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cvLmdACwiwPi"
      },
      "source": [
        "## Distil"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jaWJM-8rrGBd"
      },
      "source": [
        "# 4 Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4pIf4oLOrGbo"
      },
      "source": [
        "import glob\n",
        "llist = glob.glob(\"/content/drive/MyDrive/HateSpeech/PERFORMANCE2/*.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zuJf5nOBRPhk",
        "outputId": "4d745921-06ae-4167-f449-2dd25f109dac"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gpSNRZAxSsmA",
        "outputId": "c7e23bed-330d-4b02-e4fa-955b635f7af3"
      },
      "source": [
        "llist"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/drive/MyDrive/HateSpeech/PERFORMANCE2/ELECTRA.csv',\n",
              " '/content/drive/MyDrive/HateSpeech/PERFORMANCE2/DistilBERT.csv',\n",
              " '/content/drive/MyDrive/HateSpeech/PERFORMANCE2/RoBERTa.csv',\n",
              " '/content/drive/MyDrive/HateSpeech/PERFORMANCE2/ML_BERT.csv',\n",
              " '/content/drive/MyDrive/HateSpeech/PERFORMANCE2/GloVe_BiLSTM.csv',\n",
              " '/content/drive/MyDrive/HateSpeech/PERFORMANCE2/ML_GloVe.csv',\n",
              " '/content/drive/MyDrive/HateSpeech/PERFORMANCE2/ML_SQUEEZE.csv',\n",
              " '/content/drive/MyDrive/HateSpeech/PERFORMANCE2/MobileBERT.csv',\n",
              " '/content/drive/MyDrive/HateSpeech/PERFORMANCE2/Benchmarks.csv',\n",
              " '/content/drive/MyDrive/HateSpeech/PERFORMANCE2/Benchmarks_std.csv',\n",
              " '/content/drive/MyDrive/HateSpeech/PERFORMANCE2/ML_ELELECTRA.csv']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zyDh8gcxSWmH",
        "outputId": "af13c8fc-e41d-4131-d1cf-8e0ba0b73a19"
      },
      "source": [
        "llist.pop(-2)\n",
        "llist.pop(-2)\n",
        "llist"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/drive/MyDrive/HateSpeech/PERFORMANCE2/ELECTRA.csv',\n",
              " '/content/drive/MyDrive/HateSpeech/PERFORMANCE2/DistilBERT.csv',\n",
              " '/content/drive/MyDrive/HateSpeech/PERFORMANCE2/RoBERTa.csv',\n",
              " '/content/drive/MyDrive/HateSpeech/PERFORMANCE2/ML_BERT.csv',\n",
              " '/content/drive/MyDrive/HateSpeech/PERFORMANCE2/GloVe_BiLSTM.csv',\n",
              " '/content/drive/MyDrive/HateSpeech/PERFORMANCE2/ML_GloVe.csv',\n",
              " '/content/drive/MyDrive/HateSpeech/PERFORMANCE2/ML_SQUEEZE.csv',\n",
              " '/content/drive/MyDrive/HateSpeech/PERFORMANCE2/MobileBERT.csv',\n",
              " '/content/drive/MyDrive/HateSpeech/PERFORMANCE2/ML_ELELECTRA.csv']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hgn2hLagrOw6"
      },
      "source": [
        "import pandas as pd\n",
        "temp = pd.read_csv(llist[0])\n",
        "for ll in llist[1:]:\n",
        "  temp = pd.concat([temp,pd.read_csv(ll)])\n",
        "temp = temp.iloc[:,1:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4lriUuEQRWFA",
        "outputId": "c5476e3f-ebd1-45c6-fe6b-c37331bc2728"
      },
      "source": [
        "temp['Model'].unique()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['ELECTRA', 'DistilBERT', 'RoBERTa',\n",
              "       'LogisticRegression_BERT_EMBED',\n",
              "       'RandomForestClassifier_BERT_EMBED', 'LGBMClassifier_BERT_EMBED',\n",
              "       'BiLSTM+GloVe(10)', 'RandomForestClassifier_GloVe_EMBED',\n",
              "       'LGBMClassifier_GloVe_EMBED', 'LogisticRegression_SQUEEZE',\n",
              "       'RandomForestClassifier_SQUEEZE', 'LGBMClassifier_SQUEEZE',\n",
              "       'MobileBERT', 'LogisticRegression_ELECTRA',\n",
              "       'RandomForestClassifier_ELECTRA', 'LGBMClassifier_ELECTRA'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gx4gXo8Nrfis",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "outputId": "3f50ff91-c37c-4f57-a022-59f9aeb67323"
      },
      "source": [
        "temp.sort_values('Val_Score(ROC_AUC)',ascending=False)[['Model','Val_Score(ROC_AUC)','Val_Score(F1)','Inference_Time']].dropna()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Val_Score(ROC_AUC)</th>\n",
              "      <th>Val_Score(F1)</th>\n",
              "      <th>Inference_Time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>LGBMClassifier_ELECTRA</td>\n",
              "      <td>0.962501</td>\n",
              "      <td>0.897978</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>LogisticRegression_ELECTRA</td>\n",
              "      <td>0.962479</td>\n",
              "      <td>0.896427</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ELECTRA</td>\n",
              "      <td>0.960681</td>\n",
              "      <td>0.896048</td>\n",
              "      <td>30.033314</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>RandomForestClassifier_ELECTRA</td>\n",
              "      <td>0.960232</td>\n",
              "      <td>0.895416</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>DistilBERT</td>\n",
              "      <td>0.952547</td>\n",
              "      <td>0.879108</td>\n",
              "      <td>28.073447</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>BiLSTM+GloVe(10)</td>\n",
              "      <td>0.936699</td>\n",
              "      <td>0.864514</td>\n",
              "      <td>8.134799</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>LogisticRegression_BERT_EMBED</td>\n",
              "      <td>0.920272</td>\n",
              "      <td>0.844208</td>\n",
              "      <td>0.048613</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>LogisticRegression_SQUEEZE</td>\n",
              "      <td>0.920272</td>\n",
              "      <td>0.844208</td>\n",
              "      <td>0.043455</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>LGBMClassifier_BERT_EMBED</td>\n",
              "      <td>0.915230</td>\n",
              "      <td>0.836876</td>\n",
              "      <td>0.016189</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>LGBMClassifier_SQUEEZE</td>\n",
              "      <td>0.915230</td>\n",
              "      <td>0.836876</td>\n",
              "      <td>0.014264</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>RandomForestClassifier_SQUEEZE</td>\n",
              "      <td>0.903191</td>\n",
              "      <td>0.824184</td>\n",
              "      <td>0.123433</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>RandomForestClassifier_BERT_EMBED</td>\n",
              "      <td>0.903100</td>\n",
              "      <td>0.824437</td>\n",
              "      <td>0.123162</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>LGBMClassifier_GloVe_EMBED</td>\n",
              "      <td>0.878974</td>\n",
              "      <td>0.781779</td>\n",
              "      <td>0.107572</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>RandomForestClassifier_GloVe_EMBED</td>\n",
              "      <td>0.815871</td>\n",
              "      <td>0.724687</td>\n",
              "      <td>0.473680</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>RoBERTa</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.666350</td>\n",
              "      <td>74.460967</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>MobileBERT</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.673301</td>\n",
              "      <td>128.829436</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                Model  ...  Inference_Time\n",
              "2              LGBMClassifier_ELECTRA  ...        0.000000\n",
              "0          LogisticRegression_ELECTRA  ...        0.000000\n",
              "0                             ELECTRA  ...       30.033314\n",
              "1      RandomForestClassifier_ELECTRA  ...        0.000000\n",
              "0                          DistilBERT  ...       28.073447\n",
              "0                    BiLSTM+GloVe(10)  ...        8.134799\n",
              "0       LogisticRegression_BERT_EMBED  ...        0.048613\n",
              "0          LogisticRegression_SQUEEZE  ...        0.043455\n",
              "2           LGBMClassifier_BERT_EMBED  ...        0.016189\n",
              "2              LGBMClassifier_SQUEEZE  ...        0.014264\n",
              "1      RandomForestClassifier_SQUEEZE  ...        0.123433\n",
              "1   RandomForestClassifier_BERT_EMBED  ...        0.123162\n",
              "1          LGBMClassifier_GloVe_EMBED  ...        0.107572\n",
              "0  RandomForestClassifier_GloVe_EMBED  ...        0.473680\n",
              "0                             RoBERTa  ...       74.460967\n",
              "0                          MobileBERT  ...      128.829436\n",
              "\n",
              "[16 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    }
  ]
}