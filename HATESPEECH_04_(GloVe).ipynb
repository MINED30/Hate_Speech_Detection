{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HATESPEECH_04_(GloVe).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p4XSAMh_Wl53"
      },
      "source": [
        "# Load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J7MBpMsRWQle"
      },
      "source": [
        "import pandas as pd\n",
        "df_cleaned = pd.read_csv(\"/content/drive/MyDrive/HateSpeech/TODA(CLEANED)/BERT/TODA_CLEANED_01.csv\").iloc[:,1:]\n",
        "df_cleaned = df_cleaned.dropna()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jeYOT4UaWpc8"
      },
      "source": [
        "df_typo = pd.read_csv(\"/content/drive/MyDrive/HateSpeech/TODA(CLEANED)/BERT/TODA_TYPO_01.csv\").iloc[:,1:]\n",
        "df_typo = df_typo.dropna()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 621
        },
        "id": "SziY7nctWrL-",
        "outputId": "8c467971-6c43-48b2-face-62b23b142c93"
      },
      "source": [
        "# print(df_cleaned.shape, df_typo.shape)\n",
        "# pd.concat([df_typo.sample(5,random_state=2),df_cleaned.sample(5,random_state=2)]).sort_index()\n",
        "print(df_typo.shape)\n",
        "df_typo"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(321596, 7)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text_raw</th>\n",
              "      <th>text_cleaned</th>\n",
              "      <th>typo_corrected</th>\n",
              "      <th>tokens_raw</th>\n",
              "      <th>tokens_stop</th>\n",
              "      <th>tokens_stems</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>@BreitbartNews Idiots seem to come out of the ...</td>\n",
              "      <td>idiots seem to come out of the woodwork  it h...</td>\n",
              "      <td>idiots seem to come out of the woodwork  it h...</td>\n",
              "      <td>[' ', 'idiots', 'seem', 'to', 'come', 'out', '...</td>\n",
              "      <td>['idiots', 'come', 'woodwork', 'threatens', 'p...</td>\n",
              "      <td>['idiot', 'come', 'woodwork', 'threaten', 'pre...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>russia as a huge black hole where everything d...</td>\n",
              "      <td>russia as a huge black hole where everything d...</td>\n",
              "      <td>russia as a huge black hole where everything d...</td>\n",
              "      <td>['russia', 'as', 'a', 'huge', 'black', 'hole',...</td>\n",
              "      <td>['russia', 'huge', 'black', 'hole', 'disappear...</td>\n",
              "      <td>['russia', 'huge', 'black', 'hole', 'disappear...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>@user so much stuff happening in florida! firs...</td>\n",
              "      <td>so much stuff happening in florida! first orl...</td>\n",
              "      <td>so much stuff happening in florida! first orl...</td>\n",
              "      <td>[' ', 'so', 'much', 'stuff', 'happening', 'in'...</td>\n",
              "      <td>['stuff', 'happening', 'florida', 'orlando', '...</td>\n",
              "      <td>['stuff', 'happen', 'florida', 'orlando', 'sho...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>@user #pennydreadful a long, dark love poem ð...</td>\n",
              "      <td>pennydreadful a long dark love poem  i agree...</td>\n",
              "      <td>pennydreadful a long dark love poem  i agree...</td>\n",
              "      <td>['  ', 'pennydreadful', 'a', 'long', 'dark', '...</td>\n",
              "      <td>['pennydreadful', 'long', 'dark', 'love', 'poe...</td>\n",
              "      <td>['pennydread', 'long', 'dark', 'love', 'poem',...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>@user @user @user this is how i wanted to spnd...</td>\n",
              "      <td>this is how i wanted to spnd father's day w...</td>\n",
              "      <td>this is how i wanted to send father's day w...</td>\n",
              "      <td>['   ', 'this', 'is', 'how', 'i', 'wanted', 't...</td>\n",
              "      <td>['wanted', 'send', 'father', 'day', 'wind', 'b...</td>\n",
              "      <td>['want', 'send', 'father', 'day', 'wind', 'boy...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>321711</th>\n",
              "      <td>https://t.co/P4TPfJT2Bb #TreCru https://t.co/g...</td>\n",
              "      <td>trecru</td>\n",
              "      <td>record</td>\n",
              "      <td>[' ', 'record']</td>\n",
              "      <td>['record']</td>\n",
              "      <td>['record']</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>321712</th>\n",
              "      <td>whereas East Asians came from East Africa,</td>\n",
              "      <td>whereas east asians came from east africa</td>\n",
              "      <td>whereas east asians came from east africa</td>\n",
              "      <td>['whereas', 'east', 'asians', 'came', 'from', ...</td>\n",
              "      <td>['east', 'asians', 'came', 'east', 'africa']</td>\n",
              "      <td>['east', 'asian', 'came', 'east', 'africa']</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>321713</th>\n",
              "      <td>@AndrewBLeh @N7Kopper @nitramy Ever play Rambo...</td>\n",
              "      <td>ever play rambo on old nes by any chance?</td>\n",
              "      <td>ever play rambo on old nes by any chance?</td>\n",
              "      <td>['   ', 'ever', 'play', 'rambo', 'on', 'old', ...</td>\n",
              "      <td>['play', 'rambo', 'old', 'nes', 'chance']</td>\n",
              "      <td>['play', 'rambo', 'old', 'ne', 'chanc']</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>321714</th>\n",
              "      <td>Merger \\n\\nIf this article is to avoid being m...</td>\n",
              "      <td>merger if this article is to avoid being merge...</td>\n",
              "      <td>merger if this article is to avoid being merge...</td>\n",
              "      <td>['merger', 'if', 'this', 'article', 'is', 'to'...</td>\n",
              "      <td>['merger', 'article', 'avoid', 'merged', 'hist...</td>\n",
              "      <td>['merger', 'articl', 'avoid', 'merg', 'histori...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>321715</th>\n",
              "      <td>Zoe Quinn and other female game developers spe...</td>\n",
              "      <td>zoe quinn and other female game developers spe...</td>\n",
              "      <td>zoe quinn and other female game developers spe...</td>\n",
              "      <td>['zoe', 'quinn', 'and', 'other', 'female', 'ga...</td>\n",
              "      <td>['zoe', 'quinn', 'female', 'game', 'developers...</td>\n",
              "      <td>['zoe', 'quinn', 'femal', 'game', 'develop', '...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>321596 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 text_raw  ... class\n",
              "0       @BreitbartNews Idiots seem to come out of the ...  ...     1\n",
              "1       russia as a huge black hole where everything d...  ...     0\n",
              "2       @user so much stuff happening in florida! firs...  ...     0\n",
              "3        @user #pennydreadful a long, dark love poem ð...  ...     0\n",
              "4       @user @user @user this is how i wanted to spnd...  ...     0\n",
              "...                                                   ...  ...   ...\n",
              "321711  https://t.co/P4TPfJT2Bb #TreCru https://t.co/g...  ...     0\n",
              "321712         whereas East Asians came from East Africa,  ...     0\n",
              "321713  @AndrewBLeh @N7Kopper @nitramy Ever play Rambo...  ...     1\n",
              "321714  Merger \\n\\nIf this article is to avoid being m...  ...     0\n",
              "321715  Zoe Quinn and other female game developers spe...  ...     0\n",
              "\n",
              "[321596 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m-jAHTKeW9O2"
      },
      "source": [
        "X_cleaned = df_typo['text_cleaned']\n",
        "X_typo = df_typo['typo_corrected']\n",
        "y = df_typo['class']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jdzzi-mrXLdm",
        "outputId": "e4cac07a-8a67-46e8-ad71-6a1fd9995163"
      },
      "source": [
        "X_cleaned"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0          idiots seem to come out of the woodwork  it h...\n",
              "1         russia as a huge black hole where everything d...\n",
              "2          so much stuff happening in florida! first orl...\n",
              "3           pennydreadful a long dark love poem  i agree...\n",
              "4            this is how i wanted to spnd father's day w...\n",
              "                                ...                        \n",
              "321711                                              trecru \n",
              "321712            whereas east asians came from east africa\n",
              "321713            ever play rambo on old nes by any chance?\n",
              "321714    merger if this article is to avoid being merge...\n",
              "321715    zoe quinn and other female game developers spe...\n",
              "Name: text_cleaned, Length: 321596, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iqCo3a3xYOy-"
      },
      "source": [
        "## KFOLD"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2bAr_Dz_X03m",
        "outputId": "324a4c02-f680-4982-edb6-a7f78b393fb1"
      },
      "source": [
        "import ast\n",
        "from sklearn.model_selection import KFold\n",
        "# K_Fold Cross Validation\n",
        "df_typo['tokens_raw'] = df_typo['tokens_raw'].apply(lambda x : ast.literal_eval(x))\n",
        "kf = KFold(n_splits=5,random_state=42)\n",
        "K_FOLD_LIST = []\n",
        "k=1\n",
        "for train_index, test_index in kf.split(df_cleaned):\n",
        "  K_FOLD_LIST.append([train_index, test_index,k,df_typo['tokens_raw'].iloc[test_index].apply(len).sum()])\n",
        "  k+=1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cKARrkfwYL7u",
        "outputId": "9d55f213-6d68-47ed-d144-2b009a4543d7"
      },
      "source": [
        "print(\"train index\\t\\t\\t\\t\\ttest index\\t\\t\\t\\t\\tk   word nums\")\n",
        "print(K_FOLD_LIST[0][0],K_FOLD_LIST[0][1],\"     \",K_FOLD_LIST[0][2],K_FOLD_LIST[0][3])\n",
        "print(K_FOLD_LIST[1][0],K_FOLD_LIST[1][1],K_FOLD_LIST[1][2],K_FOLD_LIST[1][3])\n",
        "print(K_FOLD_LIST[2][0],K_FOLD_LIST[2][1],K_FOLD_LIST[2][2],K_FOLD_LIST[2][3])\n",
        "print(K_FOLD_LIST[3][0],K_FOLD_LIST[3][1],K_FOLD_LIST[3][2],K_FOLD_LIST[3][3])\n",
        "print(K_FOLD_LIST[4][0],K_FOLD_LIST[4][1],K_FOLD_LIST[4][2],K_FOLD_LIST[4][3])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train index\t\t\t\t\ttest index\t\t\t\t\tk   word nums\n",
            "[ 64320  64321  64322 ... 321593 321594 321595] [    0     1     2 ... 64317 64318 64319]       1 1955231\n",
            "[     0      1      2 ... 321593 321594 321595] [ 64320  64321  64322 ... 128636 128637 128638] 2 1939953\n",
            "[     0      1      2 ... 321593 321594 321595] [128639 128640 128641 ... 192955 192956 192957] 3 1951304\n",
            "[     0      1      2 ... 321593 321594 321595] [192958 192959 192960 ... 257274 257275 257276] 4 1941812\n",
            "[     0      1      2 ... 257274 257275 257276] [257277 257278 257279 ... 321593 321594 321595] 5 1935521\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9WIsXB5EpxlW",
        "outputId": "5983f6e3-d4d6-46e3-b7fd-0f7f5ff0a585"
      },
      "source": [
        "max(df_typo['tokens_raw'].apply(len))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "235"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AISJF-LsoDuW"
      },
      "source": [
        "## GloVe"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E1uhlVHIohXe"
      },
      "source": [
        "## Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DI8NKqZtohMb"
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "max_features=100000\n",
        "sequence_length = 235\n",
        "\n",
        "tokenizer_clean = Tokenizer(num_words=max_features, split=' ', oov_token='<unw>', filters=' ')\n",
        "tokenizer_typo = Tokenizer(num_words=max_features, split=' ', oov_token='<unw>', filters=' ')\n",
        "\n",
        "tokenizer_clean.fit_on_texts(X_cleaned)\n",
        "tokenizer_typo.fit_on_texts(X_typo)\n",
        "\n",
        "# this takes our sentences and replaces each word with an integer\n",
        "X_clean_token = tokenizer_clean.texts_to_sequences(X_cleaned)\n",
        "X_typo_token = tokenizer_typo.texts_to_sequences(X_typo)\n",
        "\n",
        "# we then pad the sequences so they're all the same length (sequence_length)\n",
        "X_clean_token = pad_sequences(X_clean_token, sequence_length)\n",
        "X_typo_token = pad_sequences(X_typo_token, sequence_length)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4mmOpeFGs8QH"
      },
      "source": [
        "dataset_list = [X_clean_token,X_typo_token]\n",
        "dataset_name = [\"Clean\",\"Typo\"]\n",
        "\n",
        "dataset = {na:li for na,li in zip(dataset_name,dataset_list)}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bORulv6RpVG3"
      },
      "source": [
        "## Embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P-B1glKQoFZ-",
        "outputId": "151dcd13-6747-480d-91b0-0ced7b9d339a"
      },
      "source": [
        "import numpy as np\n",
        "embeddings_index = {}\n",
        "f = open(\"/content/drive/MyDrive/HateSpeech/glove.6B.100d.txt\")\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "f.close()\n",
        "\n",
        "print('Found %s word vectors.' % len(embeddings_index))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 400000 word vectors.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "46sinqfypnNB",
        "outputId": "e3d3f155-c1a9-4679-9e8f-375001b7adaf"
      },
      "source": [
        "word_index_clean = tokenizer_clean.word_index\n",
        "word_index_typo = tokenizer_typo.word_index\n",
        "print('[CLEAN]Found %s unique tokens.' % len(word_index_clean))\n",
        "print('[TYPO ]Found %s unique tokens.' % len(word_index_typo))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[CLEAN]Found 337465 unique tokens.\n",
            "[TYPO ]Found 264425 unique tokens.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DWgriOz4qLNW",
        "outputId": "e814e831-55b3-4cb3-adc0-0b0d85c2924b"
      },
      "source": [
        "num_words_clean = min(max_features, len(word_index_clean)) + 1\n",
        "num_words_typo = min(max_features, len(word_index_typo)) + 1\n",
        "print(\"num_words_clean : \",num_words_clean)\n",
        "print(\"num_words_typo : \",num_words_typo)\n",
        "\n",
        "embedding_dim = 100\n",
        "\n",
        "# first create a matrix of zeros, this is our embedding matrix\n",
        "embedding_matrix_clean = np.zeros((num_words_clean, embedding_dim))\n",
        "embedding_matrix_typo = np.zeros((num_words_typo, embedding_dim))\n",
        "\n",
        "for word, i in word_index_clean.items():\n",
        "    if i > max_features:\n",
        "        continue\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        # we found the word - add that words vector to the matrix\n",
        "        embedding_matrix_clean[i] = embedding_vector\n",
        "    else:\n",
        "        # doesn't exist, assign a random vector\n",
        "        embedding_matrix_clean[i] = np.random.randn(embedding_dim)\n",
        "\n",
        "for word, i in word_index_typo.items():\n",
        "    if i > max_features:\n",
        "        continue\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix_typo[i] = embedding_vector\n",
        "    else:\n",
        "        embedding_matrix_typo[i] = np.random.randn(embedding_dim)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "num_words_clean :  100001\n",
            "num_words_typo :  100001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wF-JAO27rY7_",
        "outputId": "151e9875-bc4c-4b36-b54c-7f4aa02269d8"
      },
      "source": [
        "embedding_matrix_clean.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100001, 100)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hJTzSspZYTRW"
      },
      "source": [
        "# MODELING"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ejept0DqYWHe"
      },
      "source": [
        "## build LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "69mPZ3u4YU62"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.initializers import Constant\n",
        "from keras.layers import *\n",
        "\n",
        "def build_model(num_words,embedding_matrix):\n",
        "  model = Sequential()\n",
        "  model.add(Embedding(num_words,\n",
        "                      embedding_dim,\n",
        "                      embeddings_initializer=Constant(embedding_matrix),\n",
        "                      input_length=sequence_length,\n",
        "                      trainable=True))\n",
        "  model.add(SpatialDropout1D(0.2))\n",
        "  model.add(Bidirectional(CuDNNLSTM(64, return_sequences=True)))\n",
        "  model.add(Bidirectional(CuDNNLSTM(32)))\n",
        "  model.add(Dropout(0.25))\n",
        "  model.add(Dense(units=1, activation='sigmoid'))\n",
        "  model.compile(loss = 'binary_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
        "  return model\n",
        "\n",
        "model_clean = build_model(num_words_clean,embedding_matrix_clean)\n",
        "model_typo = build_model(num_words_typo,embedding_matrix_typo)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6OsTKulHsDOH",
        "outputId": "5b41de80-87a7-4914-9259-f315f69dd41a"
      },
      "source": [
        "model_clean.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_12\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_10 (Embedding)     (None, 235, 100)          10000100  \n",
            "_________________________________________________________________\n",
            "spatial_dropout1d_10 (Spatia (None, 235, 100)          0         \n",
            "_________________________________________________________________\n",
            "bidirectional_20 (Bidirectio (None, 235, 128)          84992     \n",
            "_________________________________________________________________\n",
            "bidirectional_21 (Bidirectio (None, 64)                41472     \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 10,126,629\n",
            "Trainable params: 10,126,629\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QpsG-6CNsE5_",
        "outputId": "86d7c504-23b8-4c17-c992-d8d5d9a52da8"
      },
      "source": [
        "model_typo.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_13\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_11 (Embedding)     (None, 235, 100)          10000100  \n",
            "_________________________________________________________________\n",
            "spatial_dropout1d_11 (Spatia (None, 235, 100)          0         \n",
            "_________________________________________________________________\n",
            "bidirectional_22 (Bidirectio (None, 235, 128)          84992     \n",
            "_________________________________________________________________\n",
            "bidirectional_23 (Bidirectio (None, 64)                41472     \n",
            "_________________________________________________________________\n",
            "dropout_11 (Dropout)         (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 10,126,629\n",
            "Trainable params: 10,126,629\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "utE9t2nfswDu"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-tSbD4atixm"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Swf-xUjns0av",
        "outputId": "aa53f708-de2f-4004-e6f4-0a6a0a62acf5"
      },
      "source": [
        "eval = pd.DataFrame([[np.nan for i in range(11)]])\n",
        "eval.columns = ['Model','Dataset','K_fold','Train_Score(ACC)','Train_Score(ROC_AUC)','Train_Score(F1)','Test_Score(ACC)','Test_Score(ROC_AUC)','Test_Score(F1)','Inference_Time','words_nums']\n",
        "eval = eval.iloc[1:]\n",
        "\n",
        "\n",
        "for data_name in dataset_name:\n",
        "  # Performance Base DataFrame\n",
        "  LR_list_base = ['BiLSTM+GloVe(10)']\n",
        "  LR_list_base.append(data_name)\n",
        "\n",
        "  # Load Data\n",
        "  X = dataset[data_name]\n",
        "\n",
        "  # K_Fold Cross Validation\n",
        "  for train_index, test_index, k, word_nums in K_FOLD_LIST:\n",
        "    if data_name=='Clean':\n",
        "      print(\"Model : CLEAN\")\n",
        "      LR = build_model(num_words_clean,embedding_matrix_clean)\n",
        "    elif data_name=='Typo':\n",
        "      print(\"Model : Typo\")\n",
        "      LR = build_model(num_words_typo,embedding_matrix_typo)\n",
        "    else :\n",
        "      print(\"**ERROR** Model Not Found\")\n",
        "    # Get Train, Test\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    # Fit and Inference\n",
        "    LR.fit(X_train,y_train,epochs=10,batch_size=256)\n",
        "    print(f\"{data_name} - {k} Trained\")\n",
        "    fitted = LR.predict_classes(X_train)\n",
        "    fitted_proba = LR.predict_proba(X_train)\n",
        "    start = time.time()\n",
        "    pred = LR.predict_classes(X_test)\n",
        "    inference_time = time.time()-start\n",
        "    pred_proba = LR.predict_proba(X_test)\n",
        "    print(f\"{data_name} - {k} Inferenced : {inference_time}s\",end='\\t')\n",
        "    # Evaluate\n",
        "    train_acc = accuracy_score(y_train.values,fitted)\n",
        "    train_auc = roc_auc_score(y_train.values,fitted_proba)\n",
        "    train_f1 = f1_score(y_train.values,fitted)\n",
        "    test_acc = accuracy_score(y_test.values,pred)\n",
        "    test_auc = roc_auc_score(y_test.values,pred_proba)\n",
        "    test_f1 = f1_score(y_test.values,pred)\n",
        "    print(f\"train ACC : {train_acc} test ACC : {test_acc} test F1 : {test_f1}\")\n",
        "\n",
        "    LR_list = LR_list_base.copy()\n",
        "    LR_list.append(k)\n",
        "    LR_list.append(train_acc)\n",
        "    LR_list.append(train_auc)\n",
        "    LR_list.append(train_f1)\n",
        "    LR_list.append(test_acc)\n",
        "    LR_list.append(test_auc)\n",
        "    LR_list.append(test_f1)\n",
        "    LR_list.append(inference_time)\n",
        "    LR_list.append(word_nums)\n",
        "\n",
        "    eval = eval.append(pd.DataFrame([LR_list],columns=eval.columns))\n",
        "eval"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model : CLEAN\n",
            "Epoch 1/10\n",
            "1005/1005 [==============================] - 134s 128ms/step - loss: 0.3143 - accuracy: 0.8751\n",
            "Epoch 2/10\n",
            "1005/1005 [==============================] - 127s 127ms/step - loss: 0.1907 - accuracy: 0.9264\n",
            "Epoch 3/10\n",
            "1005/1005 [==============================] - 128s 128ms/step - loss: 0.1683 - accuracy: 0.9348\n",
            "Epoch 4/10\n",
            "1005/1005 [==============================] - 129s 128ms/step - loss: 0.1495 - accuracy: 0.9419\n",
            "Epoch 5/10\n",
            "1005/1005 [==============================] - 128s 127ms/step - loss: 0.1285 - accuracy: 0.9500\n",
            "Epoch 6/10\n",
            "1005/1005 [==============================] - 126s 125ms/step - loss: 0.1143 - accuracy: 0.9555\n",
            "Epoch 7/10\n",
            "1005/1005 [==============================] - 126s 125ms/step - loss: 0.0997 - accuracy: 0.9615\n",
            "Epoch 8/10\n",
            "1005/1005 [==============================] - 126s 126ms/step - loss: 0.0888 - accuracy: 0.9661\n",
            "Epoch 9/10\n",
            "1005/1005 [==============================] - 127s 126ms/step - loss: 0.0767 - accuracy: 0.9712\n",
            "Epoch 10/10\n",
            "1005/1005 [==============================] - 127s 126ms/step - loss: 0.0684 - accuracy: 0.9743\n",
            "Clean - 1 Trained\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n",
            "/usr/local/lib/python3.7/dist-packages/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
            "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Clean - 1 Inferenced : 50.11148977279663s\ttrain ACC : 0.9839161056608468 test ACC : 0.9235385572139303 test F1 : 0.81185921958684\n",
            "Model : CLEAN\n",
            "Epoch 1/10\n",
            "1005/1005 [==============================] - 129s 125ms/step - loss: 0.3128 - accuracy: 0.8766\n",
            "Epoch 2/10\n",
            "1005/1005 [==============================] - 124s 124ms/step - loss: 0.1947 - accuracy: 0.9262\n",
            "Epoch 3/10\n",
            "1005/1005 [==============================] - 124s 124ms/step - loss: 0.1696 - accuracy: 0.9348\n",
            "Epoch 4/10\n",
            "1005/1005 [==============================] - 125s 124ms/step - loss: 0.1480 - accuracy: 0.9432\n",
            "Epoch 5/10\n",
            "1005/1005 [==============================] - 125s 125ms/step - loss: 0.1305 - accuracy: 0.9495\n",
            "Epoch 6/10\n",
            "1005/1005 [==============================] - 125s 124ms/step - loss: 0.1147 - accuracy: 0.9562\n",
            "Epoch 7/10\n",
            "1005/1005 [==============================] - 126s 126ms/step - loss: 0.1017 - accuracy: 0.9610\n",
            "Epoch 8/10\n",
            "1005/1005 [==============================] - 126s 125ms/step - loss: 0.0891 - accuracy: 0.9657\n",
            "Epoch 9/10\n",
            "1005/1005 [==============================] - 126s 125ms/step - loss: 0.0795 - accuracy: 0.9694\n",
            "Epoch 10/10\n",
            "1005/1005 [==============================] - 125s 125ms/step - loss: 0.0708 - accuracy: 0.9735\n",
            "Clean - 2 Trained\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n",
            "/usr/local/lib/python3.7/dist-packages/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
            "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Clean - 2 Inferenced : 48.75499415397644s\ttrain ACC : 0.9825752010478978 test ACC : 0.9269578196178423 test F1 : 0.8218024578971326\n",
            "Model : CLEAN\n",
            "Epoch 1/10\n",
            "1005/1005 [==============================] - 128s 124ms/step - loss: 0.3176 - accuracy: 0.8750\n",
            "Epoch 2/10\n",
            "1005/1005 [==============================] - 124s 124ms/step - loss: 0.1906 - accuracy: 0.9279\n",
            "Epoch 3/10\n",
            "1005/1005 [==============================] - 124s 124ms/step - loss: 0.1692 - accuracy: 0.9358\n",
            "Epoch 4/10\n",
            "1005/1005 [==============================] - 126s 125ms/step - loss: 0.1479 - accuracy: 0.9426\n",
            "Epoch 5/10\n",
            "1005/1005 [==============================] - 126s 126ms/step - loss: 0.1290 - accuracy: 0.9499\n",
            "Epoch 6/10\n",
            "1005/1005 [==============================] - 126s 125ms/step - loss: 0.1130 - accuracy: 0.9570\n",
            "Epoch 7/10\n",
            "1005/1005 [==============================] - 126s 125ms/step - loss: 0.0988 - accuracy: 0.9621\n",
            "Epoch 8/10\n",
            "1005/1005 [==============================] - 126s 126ms/step - loss: 0.0873 - accuracy: 0.9674\n",
            "Epoch 9/10\n",
            "1005/1005 [==============================] - 127s 126ms/step - loss: 0.0771 - accuracy: 0.9709\n",
            "Epoch 10/10\n",
            "1005/1005 [==============================] - 127s 126ms/step - loss: 0.0686 - accuracy: 0.9743\n",
            "Clean - 3 Trained\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n",
            "/usr/local/lib/python3.7/dist-packages/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
            "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Clean - 3 Inferenced : 48.175798177719116s\ttrain ACC : 0.984584708310498 test ACC : 0.9237861285156796 test F1 : 0.814486830154405\n",
            "Model : CLEAN\n",
            "Epoch 1/10\n",
            "1005/1005 [==============================] - 128s 124ms/step - loss: 0.3142 - accuracy: 0.8733\n",
            "Epoch 2/10\n",
            "1005/1005 [==============================] - 124s 124ms/step - loss: 0.1952 - accuracy: 0.9264\n",
            "Epoch 3/10\n",
            "1005/1005 [==============================] - 125s 125ms/step - loss: 0.1695 - accuracy: 0.9351\n",
            "Epoch 4/10\n",
            "1005/1005 [==============================] - 126s 126ms/step - loss: 0.1499 - accuracy: 0.9424\n",
            "Epoch 5/10\n",
            "1005/1005 [==============================] - 131s 130ms/step - loss: 0.1310 - accuracy: 0.9495\n",
            "Epoch 6/10\n",
            "1005/1005 [==============================] - 126s 125ms/step - loss: 0.1135 - accuracy: 0.9566\n",
            "Epoch 7/10\n",
            "1005/1005 [==============================] - 126s 125ms/step - loss: 0.0995 - accuracy: 0.9620\n",
            "Epoch 8/10\n",
            "1005/1005 [==============================] - 126s 126ms/step - loss: 0.0895 - accuracy: 0.9660\n",
            "Epoch 9/10\n",
            "1005/1005 [==============================] - 126s 125ms/step - loss: 0.0777 - accuracy: 0.9709\n",
            "Epoch 10/10\n",
            "1005/1005 [==============================] - 126s 126ms/step - loss: 0.0691 - accuracy: 0.9741\n",
            "Clean - 4 Trained\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n",
            "/usr/local/lib/python3.7/dist-packages/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
            "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Clean - 4 Inferenced : 48.216493368148804s\ttrain ACC : 0.9834031024926441 test ACC : 0.9227599931590976 test F1 : 0.8111457462175928\n",
            "Model : CLEAN\n",
            "Epoch 1/10\n",
            "1005/1005 [==============================] - 129s 124ms/step - loss: 0.3146 - accuracy: 0.8744\n",
            "Epoch 2/10\n",
            "1005/1005 [==============================] - 126s 125ms/step - loss: 0.1924 - accuracy: 0.9274\n",
            "Epoch 3/10\n",
            "1005/1005 [==============================] - 125s 124ms/step - loss: 0.1679 - accuracy: 0.9360\n",
            "Epoch 4/10\n",
            "1005/1005 [==============================] - 125s 125ms/step - loss: 0.1470 - accuracy: 0.9428\n",
            "Epoch 5/10\n",
            "1005/1005 [==============================] - 126s 125ms/step - loss: 0.1298 - accuracy: 0.9501\n",
            "Epoch 6/10\n",
            "1005/1005 [==============================] - 126s 126ms/step - loss: 0.1119 - accuracy: 0.9573\n",
            "Epoch 7/10\n",
            "1005/1005 [==============================] - 126s 125ms/step - loss: 0.0998 - accuracy: 0.9619\n",
            "Epoch 8/10\n",
            "1005/1005 [==============================] - 126s 126ms/step - loss: 0.0847 - accuracy: 0.9678\n",
            "Epoch 9/10\n",
            "1005/1005 [==============================] - 126s 125ms/step - loss: 0.0750 - accuracy: 0.9721\n",
            "Epoch 10/10\n",
            "1005/1005 [==============================] - 126s 126ms/step - loss: 0.0664 - accuracy: 0.9756\n",
            "Clean - 5 Trained\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n",
            "/usr/local/lib/python3.7/dist-packages/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
            "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Clean - 5 Inferenced : 47.749396324157715s\ttrain ACC : 0.9845030842243963 test ACC : 0.9233197033535969 test F1 : 0.811395793499044\n",
            "Model : Typo\n",
            "Epoch 1/10\n",
            "1005/1005 [==============================] - 129s 124ms/step - loss: 0.3180 - accuracy: 0.8752\n",
            "Epoch 2/10\n",
            "1005/1005 [==============================] - 125s 124ms/step - loss: 0.2010 - accuracy: 0.9233\n",
            "Epoch 3/10\n",
            "1005/1005 [==============================] - 125s 125ms/step - loss: 0.1764 - accuracy: 0.9309\n",
            "Epoch 4/10\n",
            "1005/1005 [==============================] - 125s 125ms/step - loss: 0.1571 - accuracy: 0.9385\n",
            "Epoch 5/10\n",
            "1005/1005 [==============================] - 126s 125ms/step - loss: 0.1363 - accuracy: 0.9472\n",
            "Epoch 6/10\n",
            "1005/1005 [==============================] - 127s 126ms/step - loss: 0.1194 - accuracy: 0.9537\n",
            "Epoch 7/10\n",
            "1005/1005 [==============================] - 127s 127ms/step - loss: 0.1076 - accuracy: 0.9587\n",
            "Epoch 8/10\n",
            "1005/1005 [==============================] - 126s 125ms/step - loss: 0.0938 - accuracy: 0.9642\n",
            "Epoch 9/10\n",
            "1005/1005 [==============================] - 126s 125ms/step - loss: 0.0818 - accuracy: 0.9690\n",
            "Epoch 10/10\n",
            "1005/1005 [==============================] - 125s 125ms/step - loss: 0.0748 - accuracy: 0.9721\n",
            "Typo - 1 Trained\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n",
            "/usr/local/lib/python3.7/dist-packages/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
            "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Typo - 1 Inferenced : 51.33200979232788s\ttrain ACC : 0.9816772648828496 test ACC : 0.921455223880597 test F1 : 0.8065849923430323\n",
            "Model : Typo\n",
            "Epoch 1/10\n",
            "1005/1005 [==============================] - 129s 124ms/step - loss: 0.3197 - accuracy: 0.8696\n",
            "Epoch 2/10\n",
            "1005/1005 [==============================] - 125s 125ms/step - loss: 0.2017 - accuracy: 0.9232\n",
            "Epoch 3/10\n",
            "1005/1005 [==============================] - 125s 124ms/step - loss: 0.1742 - accuracy: 0.9321\n",
            "Epoch 4/10\n",
            "1005/1005 [==============================] - 125s 124ms/step - loss: 0.1552 - accuracy: 0.9395\n",
            "Epoch 5/10\n",
            "1005/1005 [==============================] - 124s 124ms/step - loss: 0.1370 - accuracy: 0.9467\n",
            "Epoch 6/10\n",
            "1005/1005 [==============================] - 124s 124ms/step - loss: 0.1232 - accuracy: 0.9524\n",
            "Epoch 7/10\n",
            "1005/1005 [==============================] - 125s 124ms/step - loss: 0.1085 - accuracy: 0.9577\n",
            "Epoch 8/10\n",
            "1005/1005 [==============================] - 125s 124ms/step - loss: 0.0931 - accuracy: 0.9643\n",
            "Epoch 9/10\n",
            "1005/1005 [==============================] - 125s 124ms/step - loss: 0.0841 - accuracy: 0.9682\n",
            "Epoch 10/10\n",
            "1005/1005 [==============================] - 126s 125ms/step - loss: 0.0737 - accuracy: 0.9721\n",
            "Typo - 2 Trained\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n",
            "/usr/local/lib/python3.7/dist-packages/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
            "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Typo - 2 Inferenced : 48.417917251586914s\ttrain ACC : 0.9821359857274455 test ACC : 0.9193550894758936 test F1 : 0.8062310881990362\n",
            "Model : Typo\n",
            "Epoch 1/10\n",
            "1005/1005 [==============================] - 128s 124ms/step - loss: 0.3171 - accuracy: 0.8713\n",
            "Epoch 2/10\n",
            "1005/1005 [==============================] - 125s 124ms/step - loss: 0.1997 - accuracy: 0.9237\n",
            "Epoch 3/10\n",
            "1005/1005 [==============================] - 125s 124ms/step - loss: 0.1719 - accuracy: 0.9326\n",
            "Epoch 4/10\n",
            "1005/1005 [==============================] - 125s 124ms/step - loss: 0.1552 - accuracy: 0.9387\n",
            "Epoch 5/10\n",
            "1005/1005 [==============================] - 126s 125ms/step - loss: 0.1361 - accuracy: 0.9466\n",
            "Epoch 6/10\n",
            "1005/1005 [==============================] - 125s 125ms/step - loss: 0.1195 - accuracy: 0.9533\n",
            "Epoch 7/10\n",
            "1005/1005 [==============================] - 125s 124ms/step - loss: 0.1065 - accuracy: 0.9586\n",
            "Epoch 8/10\n",
            "1005/1005 [==============================] - 125s 125ms/step - loss: 0.0925 - accuracy: 0.9643\n",
            "Epoch 9/10\n",
            "1005/1005 [==============================] - 127s 126ms/step - loss: 0.0831 - accuracy: 0.9681\n",
            "Epoch 10/10\n",
            "1005/1005 [==============================] - 125s 125ms/step - loss: 0.0738 - accuracy: 0.9717\n",
            "Typo - 3 Trained\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n",
            "/usr/local/lib/python3.7/dist-packages/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
            "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Typo - 3 Inferenced : 48.15828251838684s\ttrain ACC : 0.9828706025023612 test ACC : 0.9212829801458357 test F1 : 0.8088496243440179\n",
            "Model : Typo\n",
            "Epoch 1/10\n",
            "1005/1005 [==============================] - 128s 124ms/step - loss: 0.3173 - accuracy: 0.8725\n",
            "Epoch 2/10\n",
            "1005/1005 [==============================] - 125s 124ms/step - loss: 0.2008 - accuracy: 0.9230\n",
            "Epoch 3/10\n",
            "1005/1005 [==============================] - 125s 125ms/step - loss: 0.1765 - accuracy: 0.9306\n",
            "Epoch 4/10\n",
            "1005/1005 [==============================] - 125s 125ms/step - loss: 0.1566 - accuracy: 0.9374\n",
            "Epoch 5/10\n",
            "1005/1005 [==============================] - 125s 124ms/step - loss: 0.1364 - accuracy: 0.9460\n",
            "Epoch 6/10\n",
            "1005/1005 [==============================] - 125s 124ms/step - loss: 0.1202 - accuracy: 0.9530\n",
            "Epoch 7/10\n",
            "1005/1005 [==============================] - 125s 125ms/step - loss: 0.1052 - accuracy: 0.9587\n",
            "Epoch 8/10\n",
            "1005/1005 [==============================] - 124s 123ms/step - loss: 0.0936 - accuracy: 0.9634\n",
            "Epoch 9/10\n",
            "1005/1005 [==============================] - 124s 124ms/step - loss: 0.0835 - accuracy: 0.9678\n",
            "Epoch 10/10\n",
            "1005/1005 [==============================] - 124s 124ms/step - loss: 0.0753 - accuracy: 0.9707\n",
            "Typo - 4 Trained\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n",
            "/usr/local/lib/python3.7/dist-packages/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
            "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Typo - 4 Inferenced : 47.15133762359619s\ttrain ACC : 0.9810904200530945 test ACC : 0.9194639220137129 test F1 : 0.8001851566116339\n",
            "Model : Typo\n",
            "Epoch 1/10\n",
            "1005/1005 [==============================] - 130s 126ms/step - loss: 0.3197 - accuracy: 0.8737\n",
            "Epoch 2/10\n",
            "1005/1005 [==============================] - 125s 124ms/step - loss: 0.2014 - accuracy: 0.9226\n",
            "Epoch 3/10\n",
            "1005/1005 [==============================] - 124s 123ms/step - loss: 0.1771 - accuracy: 0.9306\n",
            "Epoch 4/10\n",
            "1005/1005 [==============================] - 127s 126ms/step - loss: 0.1563 - accuracy: 0.9386\n",
            "Epoch 5/10\n",
            "1005/1005 [==============================] - 126s 125ms/step - loss: 0.1383 - accuracy: 0.9453\n",
            "Epoch 6/10\n",
            "1005/1005 [==============================] - 126s 125ms/step - loss: 0.1208 - accuracy: 0.9526\n",
            "Epoch 7/10\n",
            "1005/1005 [==============================] - 126s 125ms/step - loss: 0.1074 - accuracy: 0.9581\n",
            "Epoch 8/10\n",
            "1005/1005 [==============================] - 126s 125ms/step - loss: 0.0938 - accuracy: 0.9638\n",
            "Epoch 9/10\n",
            "1005/1005 [==============================] - 125s 125ms/step - loss: 0.0829 - accuracy: 0.9684\n",
            "Epoch 10/10\n",
            "1005/1005 [==============================] - 125s 124ms/step - loss: 0.0743 - accuracy: 0.9715\n",
            "Typo - 5 Trained\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n",
            "/usr/local/lib/python3.7/dist-packages/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
            "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Typo - 5 Inferenced : 47.887691497802734s\ttrain ACC : 0.9825829747703837 test ACC : 0.9156703306954399 test F1 : 0.7996601905887568\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Dataset</th>\n",
              "      <th>K_fold</th>\n",
              "      <th>Train_Score(ACC)</th>\n",
              "      <th>Train_Score(ROC_AUC)</th>\n",
              "      <th>Train_Score(F1)</th>\n",
              "      <th>Test_Score(ACC)</th>\n",
              "      <th>Test_Score(ROC_AUC)</th>\n",
              "      <th>Test_Score(F1)</th>\n",
              "      <th>Inference_Time</th>\n",
              "      <th>words_nums</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>BiLSTM+GloVe(10)</td>\n",
              "      <td>Clean</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.983916</td>\n",
              "      <td>0.998228</td>\n",
              "      <td>0.961423</td>\n",
              "      <td>0.923539</td>\n",
              "      <td>0.949479</td>\n",
              "      <td>0.811859</td>\n",
              "      <td>50.111490</td>\n",
              "      <td>1955231.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>BiLSTM+GloVe(10)</td>\n",
              "      <td>Clean</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.982575</td>\n",
              "      <td>0.997885</td>\n",
              "      <td>0.958213</td>\n",
              "      <td>0.926958</td>\n",
              "      <td>0.950719</td>\n",
              "      <td>0.821802</td>\n",
              "      <td>48.754994</td>\n",
              "      <td>1939953.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>BiLSTM+GloVe(10)</td>\n",
              "      <td>Clean</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.984585</td>\n",
              "      <td>0.998214</td>\n",
              "      <td>0.963099</td>\n",
              "      <td>0.923786</td>\n",
              "      <td>0.949220</td>\n",
              "      <td>0.814487</td>\n",
              "      <td>48.175798</td>\n",
              "      <td>1951304.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>BiLSTM+GloVe(10)</td>\n",
              "      <td>Clean</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.983403</td>\n",
              "      <td>0.998130</td>\n",
              "      <td>0.960163</td>\n",
              "      <td>0.922760</td>\n",
              "      <td>0.948057</td>\n",
              "      <td>0.811146</td>\n",
              "      <td>48.216493</td>\n",
              "      <td>1941812.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>BiLSTM+GloVe(10)</td>\n",
              "      <td>Clean</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.984503</td>\n",
              "      <td>0.998302</td>\n",
              "      <td>0.962836</td>\n",
              "      <td>0.923320</td>\n",
              "      <td>0.947658</td>\n",
              "      <td>0.811396</td>\n",
              "      <td>47.749396</td>\n",
              "      <td>1935521.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>BiLSTM+GloVe(10)</td>\n",
              "      <td>Typo</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.981677</td>\n",
              "      <td>0.997707</td>\n",
              "      <td>0.955973</td>\n",
              "      <td>0.921455</td>\n",
              "      <td>0.944601</td>\n",
              "      <td>0.806585</td>\n",
              "      <td>51.332010</td>\n",
              "      <td>1955231.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>BiLSTM+GloVe(10)</td>\n",
              "      <td>Typo</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.982136</td>\n",
              "      <td>0.997643</td>\n",
              "      <td>0.957404</td>\n",
              "      <td>0.919355</td>\n",
              "      <td>0.945228</td>\n",
              "      <td>0.806231</td>\n",
              "      <td>48.417917</td>\n",
              "      <td>1939953.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>BiLSTM+GloVe(10)</td>\n",
              "      <td>Typo</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.982871</td>\n",
              "      <td>0.997831</td>\n",
              "      <td>0.959051</td>\n",
              "      <td>0.921283</td>\n",
              "      <td>0.945408</td>\n",
              "      <td>0.808850</td>\n",
              "      <td>48.158283</td>\n",
              "      <td>1951304.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>BiLSTM+GloVe(10)</td>\n",
              "      <td>Typo</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.981090</td>\n",
              "      <td>0.997739</td>\n",
              "      <td>0.954449</td>\n",
              "      <td>0.919464</td>\n",
              "      <td>0.941540</td>\n",
              "      <td>0.800185</td>\n",
              "      <td>47.151338</td>\n",
              "      <td>1941812.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>BiLSTM+GloVe(10)</td>\n",
              "      <td>Typo</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.982583</td>\n",
              "      <td>0.997869</td>\n",
              "      <td>0.958819</td>\n",
              "      <td>0.915670</td>\n",
              "      <td>0.942256</td>\n",
              "      <td>0.799660</td>\n",
              "      <td>47.887691</td>\n",
              "      <td>1935521.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              Model Dataset  K_fold  ...  Test_Score(F1)  Inference_Time  words_nums\n",
              "0  BiLSTM+GloVe(10)   Clean     1.0  ...        0.811859       50.111490   1955231.0\n",
              "0  BiLSTM+GloVe(10)   Clean     2.0  ...        0.821802       48.754994   1939953.0\n",
              "0  BiLSTM+GloVe(10)   Clean     3.0  ...        0.814487       48.175798   1951304.0\n",
              "0  BiLSTM+GloVe(10)   Clean     4.0  ...        0.811146       48.216493   1941812.0\n",
              "0  BiLSTM+GloVe(10)   Clean     5.0  ...        0.811396       47.749396   1935521.0\n",
              "0  BiLSTM+GloVe(10)    Typo     1.0  ...        0.806585       51.332010   1955231.0\n",
              "0  BiLSTM+GloVe(10)    Typo     2.0  ...        0.806231       48.417917   1939953.0\n",
              "0  BiLSTM+GloVe(10)    Typo     3.0  ...        0.808850       48.158283   1951304.0\n",
              "0  BiLSTM+GloVe(10)    Typo     4.0  ...        0.800185       47.151338   1941812.0\n",
              "0  BiLSTM+GloVe(10)    Typo     5.0  ...        0.799660       47.887691   1935521.0\n",
              "\n",
              "[10 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RcvQhm8qsIrC"
      },
      "source": [
        "eval.to_csv(\"/content/drive/MyDrive/HateSpeech/PERFORMANCE/bilstm_performance1.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ctstAUNjfXN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358
        },
        "outputId": "fd62a984-6cbe-4eb8-f0be-5956f55fcf5b"
      },
      "source": [
        "eval"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Dataset</th>\n",
              "      <th>K_fold</th>\n",
              "      <th>Train_Score(ACC)</th>\n",
              "      <th>Train_Score(ROC_AUC)</th>\n",
              "      <th>Train_Score(F1)</th>\n",
              "      <th>Test_Score(ACC)</th>\n",
              "      <th>Test_Score(ROC_AUC)</th>\n",
              "      <th>Test_Score(F1)</th>\n",
              "      <th>Inference_Time</th>\n",
              "      <th>words_nums</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>BiLSTM+GloVe(10)</td>\n",
              "      <td>Clean</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.983916</td>\n",
              "      <td>0.998228</td>\n",
              "      <td>0.961423</td>\n",
              "      <td>0.923539</td>\n",
              "      <td>0.949479</td>\n",
              "      <td>0.811859</td>\n",
              "      <td>50.111490</td>\n",
              "      <td>1955231.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>BiLSTM+GloVe(10)</td>\n",
              "      <td>Clean</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.982575</td>\n",
              "      <td>0.997885</td>\n",
              "      <td>0.958213</td>\n",
              "      <td>0.926958</td>\n",
              "      <td>0.950719</td>\n",
              "      <td>0.821802</td>\n",
              "      <td>48.754994</td>\n",
              "      <td>1939953.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>BiLSTM+GloVe(10)</td>\n",
              "      <td>Clean</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.984585</td>\n",
              "      <td>0.998214</td>\n",
              "      <td>0.963099</td>\n",
              "      <td>0.923786</td>\n",
              "      <td>0.949220</td>\n",
              "      <td>0.814487</td>\n",
              "      <td>48.175798</td>\n",
              "      <td>1951304.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>BiLSTM+GloVe(10)</td>\n",
              "      <td>Clean</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.983403</td>\n",
              "      <td>0.998130</td>\n",
              "      <td>0.960163</td>\n",
              "      <td>0.922760</td>\n",
              "      <td>0.948057</td>\n",
              "      <td>0.811146</td>\n",
              "      <td>48.216493</td>\n",
              "      <td>1941812.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>BiLSTM+GloVe(10)</td>\n",
              "      <td>Clean</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.984503</td>\n",
              "      <td>0.998302</td>\n",
              "      <td>0.962836</td>\n",
              "      <td>0.923320</td>\n",
              "      <td>0.947658</td>\n",
              "      <td>0.811396</td>\n",
              "      <td>47.749396</td>\n",
              "      <td>1935521.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>BiLSTM+GloVe(10)</td>\n",
              "      <td>Typo</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.981677</td>\n",
              "      <td>0.997707</td>\n",
              "      <td>0.955973</td>\n",
              "      <td>0.921455</td>\n",
              "      <td>0.944601</td>\n",
              "      <td>0.806585</td>\n",
              "      <td>51.332010</td>\n",
              "      <td>1955231.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>BiLSTM+GloVe(10)</td>\n",
              "      <td>Typo</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.982136</td>\n",
              "      <td>0.997643</td>\n",
              "      <td>0.957404</td>\n",
              "      <td>0.919355</td>\n",
              "      <td>0.945228</td>\n",
              "      <td>0.806231</td>\n",
              "      <td>48.417917</td>\n",
              "      <td>1939953.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>BiLSTM+GloVe(10)</td>\n",
              "      <td>Typo</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.982871</td>\n",
              "      <td>0.997831</td>\n",
              "      <td>0.959051</td>\n",
              "      <td>0.921283</td>\n",
              "      <td>0.945408</td>\n",
              "      <td>0.808850</td>\n",
              "      <td>48.158283</td>\n",
              "      <td>1951304.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>BiLSTM+GloVe(10)</td>\n",
              "      <td>Typo</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.981090</td>\n",
              "      <td>0.997739</td>\n",
              "      <td>0.954449</td>\n",
              "      <td>0.919464</td>\n",
              "      <td>0.941540</td>\n",
              "      <td>0.800185</td>\n",
              "      <td>47.151338</td>\n",
              "      <td>1941812.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>BiLSTM+GloVe(10)</td>\n",
              "      <td>Typo</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.982583</td>\n",
              "      <td>0.997869</td>\n",
              "      <td>0.958819</td>\n",
              "      <td>0.915670</td>\n",
              "      <td>0.942256</td>\n",
              "      <td>0.799660</td>\n",
              "      <td>47.887691</td>\n",
              "      <td>1935521.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              Model Dataset  K_fold  ...  Test_Score(F1)  Inference_Time  words_nums\n",
              "0  BiLSTM+GloVe(10)   Clean     1.0  ...        0.811859       50.111490   1955231.0\n",
              "0  BiLSTM+GloVe(10)   Clean     2.0  ...        0.821802       48.754994   1939953.0\n",
              "0  BiLSTM+GloVe(10)   Clean     3.0  ...        0.814487       48.175798   1951304.0\n",
              "0  BiLSTM+GloVe(10)   Clean     4.0  ...        0.811146       48.216493   1941812.0\n",
              "0  BiLSTM+GloVe(10)   Clean     5.0  ...        0.811396       47.749396   1935521.0\n",
              "0  BiLSTM+GloVe(10)    Typo     1.0  ...        0.806585       51.332010   1955231.0\n",
              "0  BiLSTM+GloVe(10)    Typo     2.0  ...        0.806231       48.417917   1939953.0\n",
              "0  BiLSTM+GloVe(10)    Typo     3.0  ...        0.808850       48.158283   1951304.0\n",
              "0  BiLSTM+GloVe(10)    Typo     4.0  ...        0.800185       47.151338   1941812.0\n",
              "0  BiLSTM+GloVe(10)    Typo     5.0  ...        0.799660       47.887691   1935521.0\n",
              "\n",
              "[10 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3-JWe9PqlSYd"
      },
      "source": [
        "df = pd.read_csv(\"/content/trial_en.tsv\",sep='\\t')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yjZYlYGdmxZO"
      },
      "source": [
        "import re\n",
        "def preprocess(text):\n",
        "  # URL 제거\n",
        "  text = re.sub('http\\S+', '', text)\n",
        "  # 멘션 제거\n",
        "  text = re.sub('@\\S+', '', text)\n",
        "  # 해쉬 및 특수문자 제거\n",
        "  delete_e = re.compile(\"[^a-zA-Z0-9\\!\\?\\$\\%\\' ]\")\n",
        "  text = delete_e.sub(\"\",text)\n",
        "  text = text.lower()\n",
        "  return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RVFmU0DXmuGB"
      },
      "source": [
        "df['cleaned'] = df['text'].apply(preprocess)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        },
        "id": "VTJtuA5qmOrQ",
        "outputId": "eabf2a82-63ae-4604-d0ba-9e1f000e26f0"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>HS</th>\n",
              "      <th>TR</th>\n",
              "      <th>AG</th>\n",
              "      <th>prediction</th>\n",
              "      <th>cleaned</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>RT @vaintshit:  shut the fuck up and come suck...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>rt   shut the fuck up and come suck my dick</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>@ArianasBotch Ok if you fucking said leave blo...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>ok if you fucking said leave block me but dm ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>@CyV_SW Wow mo cock got hard. Want to pull you...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>wow mo cock got hard want to pull your pantie...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Ill kill the bitch (chloe) when your not home ...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>ill kill the bitch chloe when your not home  i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>...............................'I get to rape ...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>'i get to rape beautiful women and that's why ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>96</td>\n",
              "      <td>Russia has said that within the coming months,...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>russia has said that within the coming months ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>97</td>\n",
              "      <td>Orthodox Church attacked in hate crime against...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>orthodox church attacked in hate crime against...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>98</td>\n",
              "      <td>UK MPs probe unpublished UN â€˜sex-for-foodâ€™...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>uk mps probe unpublished un sexforfood finding...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>99</td>\n",
              "      <td>\\\"Large areas have been evacuated and people w...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>large areas have been evacuated and people wer...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>100</td>\n",
              "      <td>what a f**king political muppet. https://t.co/...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>what a fking political muppet</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     id  ...                                            cleaned\n",
              "0     1  ...       rt   shut the fuck up and come suck my dick \n",
              "1     2  ...   ok if you fucking said leave block me but dm ...\n",
              "2     3  ...   wow mo cock got hard want to pull your pantie...\n",
              "3     4  ...  ill kill the bitch chloe when your not home  i...\n",
              "4     5  ...  'i get to rape beautiful women and that's why ...\n",
              "..  ...  ...                                                ...\n",
              "95   96  ...  russia has said that within the coming months ...\n",
              "96   97  ...  orthodox church attacked in hate crime against...\n",
              "97   98  ...  uk mps probe unpublished un sexforfood finding...\n",
              "98   99  ...  large areas have been evacuated and people wer...\n",
              "99  100  ...                     what a fking political muppet \n",
              "\n",
              "[100 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XTs7SH0rmSiQ",
        "outputId": "88d42b44-4de4-4252-ac0b-f7ba111661f6"
      },
      "source": [
        "df['HS'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    50\n",
              "0    50\n",
              "Name: HS, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 168
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zdvwUeD4pAU_",
        "outputId": "a09d6f49-f89c-44bd-8c34-217f0aaa2864"
      },
      "source": [
        "df['prediction'] = LR.predict_classes(pad_sequences(tokenizer_clean.texts_to_sequences(df['cleaned']), sequence_length))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d4xTdylqmYeM",
        "outputId": "75a01ca7-e6e3-4c0a-e978-dcab07380694"
      },
      "source": [
        "df['prediction'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    60\n",
              "0    40\n",
              "Name: prediction, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 236
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JI4crrtjnBPI",
        "outputId": "169d3227-6ba1-4ddc-b6ca-ef4b7dafd2e8"
      },
      "source": [
        "f1_score(df['HS'],df['prediction'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5818181818181818"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 237
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KXzsS4vjqIFZ",
        "outputId": "31771670-f170-4f1f-fcce-c668a9c0874a"
      },
      "source": [
        "accuracy_score(df['HS'],df['prediction'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.54"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 238
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L6BGMu2XnXRc",
        "outputId": "d1514b5c-a0c0-4594-e3c3-b355f007e766"
      },
      "source": [
        "a = df_typo[df_typo['class']==1]['class'][15000:20000]\n",
        "b = LR.predict_classes(pad_sequences(tokenizer_clean.texts_to_sequences(df_typo[df_typo['class']==1]['text_cleaned'][15000:20000]), sequence_length))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aBYnCfLnnF2a",
        "outputId": "1199fb6b-e505-4af5-f581-1a163d1b81d0"
      },
      "source": [
        "accuracy_score(a,b)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.779"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 179
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bobrCBK7nzzP",
        "outputId": "ee7cd423-f332-41c0-ad6f-3b9ef78dbd0e"
      },
      "source": [
        "f1_score(a,b)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8757729061270377"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 180
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JlJaAS7Xoceq",
        "outputId": "f0d128fe-9176-4dbf-fd47-ab35a56d9cf3"
      },
      "source": [
        "LR.fit(pad_sequences(tokenizer_clean.texts_to_sequences(pd.concat([df_typo['text_cleaned'][:30000],df_typo[df_typo['class']==1]['text_cleaned'][:30000]])), sequence_length),pd.concat([df_typo['class'][:30000],df_typo[df_typo['class']==1]['class'][:30000]]),batch_size=256)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "235/235 [==============================] - 30s 128ms/step - loss: 0.2270 - accuracy: 0.9145\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa408eeda50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 234
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SvZEGgPPD-ga"
      },
      "source": [
        "# Performance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HKVNEAP6EgRT",
        "outputId": "e188ee6e-25eb-49fd-e4b3-45be8059cafa"
      },
      "source": [
        "import glob\n",
        "per_list = glob.glob(\"/content/drive/MyDrive/HateSpeech/PERFORMANCE/*.csv\")[:-1]\n",
        "per_list"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/drive/MyDrive/HateSpeech/PERFORMANCE/logistic_performance.csv',\n",
              " '/content/drive/MyDrive/HateSpeech/PERFORMANCE/randomforest_performance.csv',\n",
              " '/content/drive/MyDrive/HateSpeech/PERFORMANCE/lgbm_performance.csv',\n",
              " '/content/drive/MyDrive/HateSpeech/PERFORMANCE/bilstm_performance.csv']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        },
        "id": "1tSn2BWzE8ih",
        "outputId": "6989bc55-ee5f-4508-fac1-287de04ab122"
      },
      "source": [
        "df = pd.read_csv(per_list[0]).iloc[:,1:]\n",
        "for d in per_list[1:]:\n",
        "  df = pd.concat([df,pd.read_csv(d).iloc[:,1:]])\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Dataset</th>\n",
              "      <th>K_fold</th>\n",
              "      <th>Train_Score(ACC)</th>\n",
              "      <th>Train_Score(ROC_AUC)</th>\n",
              "      <th>Train_Score(F1)</th>\n",
              "      <th>Test_Score(ACC)</th>\n",
              "      <th>Test_Score(ROC_AUC)</th>\n",
              "      <th>Test_Score(F1)</th>\n",
              "      <th>Inference_Time</th>\n",
              "      <th>words_nums</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>LogisticRegression</td>\n",
              "      <td>Clean_Raw</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.928011</td>\n",
              "      <td>0.962799</td>\n",
              "      <td>0.810358</td>\n",
              "      <td>0.924580</td>\n",
              "      <td>0.952188</td>\n",
              "      <td>0.799338</td>\n",
              "      <td>0.004323</td>\n",
              "      <td>1955231.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>LogisticRegression</td>\n",
              "      <td>Clean_Raw</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.927821</td>\n",
              "      <td>0.962503</td>\n",
              "      <td>0.809421</td>\n",
              "      <td>0.924735</td>\n",
              "      <td>0.953691</td>\n",
              "      <td>0.801183</td>\n",
              "      <td>0.003997</td>\n",
              "      <td>1939953.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>LogisticRegression</td>\n",
              "      <td>Clean_Raw</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.928058</td>\n",
              "      <td>0.962937</td>\n",
              "      <td>0.810174</td>\n",
              "      <td>0.923460</td>\n",
              "      <td>0.952043</td>\n",
              "      <td>0.798047</td>\n",
              "      <td>0.004046</td>\n",
              "      <td>1951304.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>LogisticRegression</td>\n",
              "      <td>Clean_Raw</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.927852</td>\n",
              "      <td>0.962681</td>\n",
              "      <td>0.809932</td>\n",
              "      <td>0.923615</td>\n",
              "      <td>0.952920</td>\n",
              "      <td>0.797960</td>\n",
              "      <td>0.004014</td>\n",
              "      <td>1941812.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>LogisticRegression</td>\n",
              "      <td>Clean_Raw</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.928365</td>\n",
              "      <td>0.963037</td>\n",
              "      <td>0.811184</td>\n",
              "      <td>0.922947</td>\n",
              "      <td>0.951012</td>\n",
              "      <td>0.796167</td>\n",
              "      <td>0.003793</td>\n",
              "      <td>1935521.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>BiLSTM+GloVe(10)</td>\n",
              "      <td>Typo</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.981677</td>\n",
              "      <td>0.997707</td>\n",
              "      <td>0.955973</td>\n",
              "      <td>0.921455</td>\n",
              "      <td>0.944601</td>\n",
              "      <td>0.806585</td>\n",
              "      <td>51.332010</td>\n",
              "      <td>1955231.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>BiLSTM+GloVe(10)</td>\n",
              "      <td>Typo</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.982136</td>\n",
              "      <td>0.997643</td>\n",
              "      <td>0.957404</td>\n",
              "      <td>0.919355</td>\n",
              "      <td>0.945228</td>\n",
              "      <td>0.806231</td>\n",
              "      <td>48.417917</td>\n",
              "      <td>1939953.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>BiLSTM+GloVe(10)</td>\n",
              "      <td>Typo</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.982871</td>\n",
              "      <td>0.997831</td>\n",
              "      <td>0.959051</td>\n",
              "      <td>0.921283</td>\n",
              "      <td>0.945408</td>\n",
              "      <td>0.808850</td>\n",
              "      <td>48.158283</td>\n",
              "      <td>1951304.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>BiLSTM+GloVe(10)</td>\n",
              "      <td>Typo</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.981090</td>\n",
              "      <td>0.997739</td>\n",
              "      <td>0.954449</td>\n",
              "      <td>0.919464</td>\n",
              "      <td>0.941540</td>\n",
              "      <td>0.800185</td>\n",
              "      <td>47.151338</td>\n",
              "      <td>1941812.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>BiLSTM+GloVe(10)</td>\n",
              "      <td>Typo</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.982583</td>\n",
              "      <td>0.997869</td>\n",
              "      <td>0.958819</td>\n",
              "      <td>0.915670</td>\n",
              "      <td>0.942256</td>\n",
              "      <td>0.799660</td>\n",
              "      <td>47.887691</td>\n",
              "      <td>1935521.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 11 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                 Model    Dataset  ...  Inference_Time  words_nums\n",
              "0   LogisticRegression  Clean_Raw  ...        0.004323   1955231.0\n",
              "1   LogisticRegression  Clean_Raw  ...        0.003997   1939953.0\n",
              "2   LogisticRegression  Clean_Raw  ...        0.004046   1951304.0\n",
              "3   LogisticRegression  Clean_Raw  ...        0.004014   1941812.0\n",
              "4   LogisticRegression  Clean_Raw  ...        0.003793   1935521.0\n",
              "..                 ...        ...  ...             ...         ...\n",
              "5     BiLSTM+GloVe(10)       Typo  ...       51.332010   1955231.0\n",
              "6     BiLSTM+GloVe(10)       Typo  ...       48.417917   1939953.0\n",
              "7     BiLSTM+GloVe(10)       Typo  ...       48.158283   1951304.0\n",
              "8     BiLSTM+GloVe(10)       Typo  ...       47.151338   1941812.0\n",
              "9     BiLSTM+GloVe(10)       Typo  ...       47.887691   1935521.0\n",
              "\n",
              "[100 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 698
        },
        "id": "jJvD78AYFONm",
        "outputId": "c3a2ec81-6270-4915-a7dc-7a0d4f788b61"
      },
      "source": [
        "df.groupby(['Model','Dataset']).mean().sort_values(\"Test_Score(F1)\",ascending=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>K_fold</th>\n",
              "      <th>Train_Score(ACC)</th>\n",
              "      <th>Train_Score(ROC_AUC)</th>\n",
              "      <th>Train_Score(F1)</th>\n",
              "      <th>Test_Score(ACC)</th>\n",
              "      <th>Test_Score(ROC_AUC)</th>\n",
              "      <th>Test_Score(F1)</th>\n",
              "      <th>Inference_Time</th>\n",
              "      <th>words_nums</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Model</th>\n",
              "      <th>Dataset</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>RandomForestClassifier</th>\n",
              "      <th>Clean_Stemming</th>\n",
              "      <td>3.0</td>\n",
              "      <td>0.991944</td>\n",
              "      <td>0.998524</td>\n",
              "      <td>0.980665</td>\n",
              "      <td>0.927064</td>\n",
              "      <td>0.950134</td>\n",
              "      <td>0.815932</td>\n",
              "      <td>0.856754</td>\n",
              "      <td>1944764.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BiLSTM+GloVe(10)</th>\n",
              "      <th>Clean</th>\n",
              "      <td>3.0</td>\n",
              "      <td>0.983796</td>\n",
              "      <td>0.998152</td>\n",
              "      <td>0.961147</td>\n",
              "      <td>0.924072</td>\n",
              "      <td>0.949026</td>\n",
              "      <td>0.814138</td>\n",
              "      <td>48.601634</td>\n",
              "      <td>1944764.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">RandomForestClassifier</th>\n",
              "      <th>Clean_Stopword</th>\n",
              "      <td>3.0</td>\n",
              "      <td>0.991046</td>\n",
              "      <td>0.998342</td>\n",
              "      <td>0.978472</td>\n",
              "      <td>0.925525</td>\n",
              "      <td>0.947295</td>\n",
              "      <td>0.812046</td>\n",
              "      <td>1.035650</td>\n",
              "      <td>1944764.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Clean_Raw</th>\n",
              "      <td>3.0</td>\n",
              "      <td>0.991352</td>\n",
              "      <td>0.998446</td>\n",
              "      <td>0.979218</td>\n",
              "      <td>0.925388</td>\n",
              "      <td>0.946973</td>\n",
              "      <td>0.811664</td>\n",
              "      <td>0.976822</td>\n",
              "      <td>1944764.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LGBMClassifier</th>\n",
              "      <th>Clean_Stemming</th>\n",
              "      <td>3.0</td>\n",
              "      <td>0.928234</td>\n",
              "      <td>0.954156</td>\n",
              "      <td>0.811448</td>\n",
              "      <td>0.925646</td>\n",
              "      <td>0.948718</td>\n",
              "      <td>0.804464</td>\n",
              "      <td>0.032878</td>\n",
              "      <td>1944764.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BiLSTM+GloVe(10)</th>\n",
              "      <th>Typo</th>\n",
              "      <td>3.0</td>\n",
              "      <td>0.982071</td>\n",
              "      <td>0.997758</td>\n",
              "      <td>0.957139</td>\n",
              "      <td>0.919446</td>\n",
              "      <td>0.943807</td>\n",
              "      <td>0.804302</td>\n",
              "      <td>48.589448</td>\n",
              "      <td>1944764.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RandomForestClassifier</th>\n",
              "      <th>Typo_Stemming</th>\n",
              "      <td>3.0</td>\n",
              "      <td>0.991827</td>\n",
              "      <td>0.998573</td>\n",
              "      <td>0.980382</td>\n",
              "      <td>0.922993</td>\n",
              "      <td>0.945579</td>\n",
              "      <td>0.803877</td>\n",
              "      <td>0.835905</td>\n",
              "      <td>1944764.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LogisticRegression</th>\n",
              "      <th>Clean_Stemming</th>\n",
              "      <td>3.0</td>\n",
              "      <td>0.928669</td>\n",
              "      <td>0.963701</td>\n",
              "      <td>0.812643</td>\n",
              "      <td>0.925018</td>\n",
              "      <td>0.954486</td>\n",
              "      <td>0.802464</td>\n",
              "      <td>0.003961</td>\n",
              "      <td>1944764.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">RandomForestClassifier</th>\n",
              "      <th>Typo_Raw</th>\n",
              "      <td>3.0</td>\n",
              "      <td>0.991536</td>\n",
              "      <td>0.998518</td>\n",
              "      <td>0.979670</td>\n",
              "      <td>0.922036</td>\n",
              "      <td>0.943658</td>\n",
              "      <td>0.802004</td>\n",
              "      <td>0.998439</td>\n",
              "      <td>1944764.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Typo_Stopword</th>\n",
              "      <td>3.0</td>\n",
              "      <td>0.991279</td>\n",
              "      <td>0.998434</td>\n",
              "      <td>0.979043</td>\n",
              "      <td>0.921840</td>\n",
              "      <td>0.943994</td>\n",
              "      <td>0.801426</td>\n",
              "      <td>1.035795</td>\n",
              "      <td>1944764.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">LogisticRegression</th>\n",
              "      <th>Clean_Stopword</th>\n",
              "      <td>3.0</td>\n",
              "      <td>0.928309</td>\n",
              "      <td>0.962935</td>\n",
              "      <td>0.811044</td>\n",
              "      <td>0.924299</td>\n",
              "      <td>0.952581</td>\n",
              "      <td>0.799868</td>\n",
              "      <td>0.003854</td>\n",
              "      <td>1944764.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Clean_Raw</th>\n",
              "      <td>3.0</td>\n",
              "      <td>0.928021</td>\n",
              "      <td>0.962791</td>\n",
              "      <td>0.810214</td>\n",
              "      <td>0.923867</td>\n",
              "      <td>0.952371</td>\n",
              "      <td>0.798539</td>\n",
              "      <td>0.004035</td>\n",
              "      <td>1944764.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"3\" valign=\"top\">LGBMClassifier</th>\n",
              "      <th>Clean_Raw</th>\n",
              "      <td>3.0</td>\n",
              "      <td>0.926398</td>\n",
              "      <td>0.949427</td>\n",
              "      <td>0.804439</td>\n",
              "      <td>0.924026</td>\n",
              "      <td>0.944095</td>\n",
              "      <td>0.797984</td>\n",
              "      <td>0.032603</td>\n",
              "      <td>1944764.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Clean_Stopword</th>\n",
              "      <td>3.0</td>\n",
              "      <td>0.926263</td>\n",
              "      <td>0.949459</td>\n",
              "      <td>0.804068</td>\n",
              "      <td>0.923936</td>\n",
              "      <td>0.944052</td>\n",
              "      <td>0.797766</td>\n",
              "      <td>0.037493</td>\n",
              "      <td>1944764.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Typo_Stemming</th>\n",
              "      <td>3.0</td>\n",
              "      <td>0.923896</td>\n",
              "      <td>0.950286</td>\n",
              "      <td>0.798296</td>\n",
              "      <td>0.921246</td>\n",
              "      <td>0.944541</td>\n",
              "      <td>0.791099</td>\n",
              "      <td>0.032954</td>\n",
              "      <td>1944764.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"3\" valign=\"top\">LogisticRegression</th>\n",
              "      <th>Typo_Stemming</th>\n",
              "      <td>3.0</td>\n",
              "      <td>0.924836</td>\n",
              "      <td>0.960643</td>\n",
              "      <td>0.801203</td>\n",
              "      <td>0.920804</td>\n",
              "      <td>0.950816</td>\n",
              "      <td>0.789912</td>\n",
              "      <td>0.003997</td>\n",
              "      <td>1944764.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Typo_Stopword</th>\n",
              "      <td>3.0</td>\n",
              "      <td>0.924865</td>\n",
              "      <td>0.960605</td>\n",
              "      <td>0.800868</td>\n",
              "      <td>0.920612</td>\n",
              "      <td>0.949699</td>\n",
              "      <td>0.788799</td>\n",
              "      <td>0.003954</td>\n",
              "      <td>1944764.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Typo_Raw</th>\n",
              "      <td>3.0</td>\n",
              "      <td>0.924528</td>\n",
              "      <td>0.960417</td>\n",
              "      <td>0.799846</td>\n",
              "      <td>0.920220</td>\n",
              "      <td>0.949477</td>\n",
              "      <td>0.787673</td>\n",
              "      <td>0.004246</td>\n",
              "      <td>1944764.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">LGBMClassifier</th>\n",
              "      <th>Typo_Raw</th>\n",
              "      <td>3.0</td>\n",
              "      <td>0.922398</td>\n",
              "      <td>0.946551</td>\n",
              "      <td>0.792082</td>\n",
              "      <td>0.920027</td>\n",
              "      <td>0.940919</td>\n",
              "      <td>0.785522</td>\n",
              "      <td>0.032530</td>\n",
              "      <td>1944764.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Typo_Stopword</th>\n",
              "      <td>3.0</td>\n",
              "      <td>0.922423</td>\n",
              "      <td>0.946388</td>\n",
              "      <td>0.792100</td>\n",
              "      <td>0.919943</td>\n",
              "      <td>0.940894</td>\n",
              "      <td>0.785310</td>\n",
              "      <td>0.032636</td>\n",
              "      <td>1944764.2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                       K_fold  ...  words_nums\n",
              "Model                  Dataset                 ...            \n",
              "RandomForestClassifier Clean_Stemming     3.0  ...   1944764.2\n",
              "BiLSTM+GloVe(10)       Clean              3.0  ...   1944764.2\n",
              "RandomForestClassifier Clean_Stopword     3.0  ...   1944764.2\n",
              "                       Clean_Raw          3.0  ...   1944764.2\n",
              "LGBMClassifier         Clean_Stemming     3.0  ...   1944764.2\n",
              "BiLSTM+GloVe(10)       Typo               3.0  ...   1944764.2\n",
              "RandomForestClassifier Typo_Stemming      3.0  ...   1944764.2\n",
              "LogisticRegression     Clean_Stemming     3.0  ...   1944764.2\n",
              "RandomForestClassifier Typo_Raw           3.0  ...   1944764.2\n",
              "                       Typo_Stopword      3.0  ...   1944764.2\n",
              "LogisticRegression     Clean_Stopword     3.0  ...   1944764.2\n",
              "                       Clean_Raw          3.0  ...   1944764.2\n",
              "LGBMClassifier         Clean_Raw          3.0  ...   1944764.2\n",
              "                       Clean_Stopword     3.0  ...   1944764.2\n",
              "                       Typo_Stemming      3.0  ...   1944764.2\n",
              "LogisticRegression     Typo_Stemming      3.0  ...   1944764.2\n",
              "                       Typo_Stopword      3.0  ...   1944764.2\n",
              "                       Typo_Raw           3.0  ...   1944764.2\n",
              "LGBMClassifier         Typo_Raw           3.0  ...   1944764.2\n",
              "                       Typo_Stopword      3.0  ...   1944764.2\n",
              "\n",
              "[20 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sET7JiidPQg7"
      },
      "source": [
        "eval = pd.DataFrame([[np.nan for i in range(11)]])\n",
        "eval.columns = ['Model','Dataset','K_fold','Train_Score(ACC)','Train_Score(ROC_AUC)','Train_Score(F1)','Test_Score(ACC)','Test_Score(ROC_AUC)','Test_Score(F1)','Inference_Time','words_nums']\n",
        "eval = eval.iloc[1:]\n",
        "\n",
        "\n",
        "for data_name in dataset_name:\n",
        "  for tokenizer, model_seq, model_name, pretrained, plat in Model_list:\n",
        "    # Performance Base DataFrame\n",
        "    LR_list_base = [model_name] # ALBERT\n",
        "    LR_list_base.append(data_name) # CLEAN\n",
        "\n",
        "    # Load Data\n",
        "    X = dataset[data_name]\n",
        "\n",
        "    # K_Fold Cross Validation\n",
        "    for train_index, test_index, k, word_nums in K_FOLD_LIST:\n",
        "      tokenizer = tokenizer.from_pretrained(pretrained)\n",
        "      LR = model.from_pretrained(pretrained)\n",
        "      optimizer = tf.keras.optimizers.Adam(learning_rate=5e-5)\n",
        "      model.compile(optimizer=optimizer, loss=model.compute_loss) # can also use any keras loss fn\n",
        "\n",
        "\n",
        "      # Get Train, Test\n",
        "      X_train, X_test = X.iloc[train_index].to_list(), X.iloc[test_index].to_list()\n",
        "      y_train, y_test = y.iloc[train_index].to_list(), y.iloc[test_index].to_list()\n",
        "\n",
        "      train_encodings = tokenizer(X_train, truncation=True, padding=True)\n",
        "      test_encodings = tokenizer(X_test, truncation=True, padding=True)\n",
        "\n",
        "      train_dataset = tf.data.Dataset.from_tensor_slices((\n",
        "          dict(train_encodings),\n",
        "          y_train\n",
        "      ))\n",
        "      test_dataset = tf.data.Dataset.from_tensor_slices((\n",
        "          dict(test_encodings),\n",
        "          y_test\n",
        "      ))\n",
        "\n",
        "      # Fit and Inference\n",
        "      model.fit(train_dataset.shuffle(1000).batch(16), epochs=1, batch_size=16)\n",
        "\n",
        "      print(f\"{data_name} - {k} Trained\")\n",
        "      fitted = LR.predict(train_dataset.shuffle(1000).batch(16))\n",
        "      fitted = tf.nn.softmax(fitted.logits, axis=1)\n",
        "      fitted_proba = fitted[:,1]\n",
        "      fitted = [np.argmax(res) for res in fitted]\n",
        "      start = time.time()\n",
        "      pred = LR.predict(test_dataset.shuffle(1000).batch(16))\n",
        "      pred = tf.nn.softmax(pred.logits, axis=1)\n",
        "      inference_time = time.time()-start\n",
        "      pred_proba = pred[:,1]\n",
        "      pred = [np.argmax(res) for res in pred_proba]\n",
        "      print(f\"{data_name} - {k} Inferenced : {inference_time}s\",end='\\t')\n",
        "      # Evaluate\n",
        "      train_acc = accuracy_score(y_train,fitted)\n",
        "      train_auc = roc_auc_score(y_train,fitted_proba)\n",
        "      train_f1 = f1_score(y_trains,fitted)\n",
        "      test_acc = accuracy_score(y_test,pred)\n",
        "      test_auc = roc_auc_score(y_test,pred_proba)\n",
        "      test_f1 = f1_score(y_test,pred)\n",
        "      print(f\"train ACC : {train_acc} test ACC : {test_acc} test F1 : {test_f1}\")\n",
        "\n",
        "      LR_list = LR_list_base.copy()\n",
        "      LR_list.append(k)\n",
        "      LR_list.append(train_acc)\n",
        "      LR_list.append(train_auc)\n",
        "      LR_list.append(train_f1)\n",
        "      LR_list.append(test_acc)\n",
        "      LR_list.append(test_auc)\n",
        "      LR_list.append(test_f1)\n",
        "      LR_list.append(inference_time)\n",
        "      LR_list.append(word_nums)\n",
        "\n",
        "      eval = eval.append(pd.DataFrame([LR_list],columns=eval.columns))\n",
        "eval"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}